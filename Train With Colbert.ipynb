{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b84ed421-c478-4163-9ac6-190defda2e72",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Train With Colbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97593488-22fb-401c-9a0e-e1c601b0fc21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import polars as pl\n",
    "import polars.selectors as cs\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, Union\n",
    "from scipy.special import softmax\n",
    "from pathlib import Path\n",
    "\n",
    "from colbert.infra import Run, RunConfig, ColBERTConfig\n",
    "from colbert.data import Queries\n",
    "from colbert import Indexer, Searcher\n",
    "\n",
    "import wandb\n",
    "import torch\n",
    "import evaluate\n",
    "from transformers import AutoTokenizer, AutoModelForMultipleChoice, Trainer, TrainingArguments, \\\n",
    "                         IntervalStrategy, get_linear_schedule_with_warmup\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n",
    "from transformers.utils.notebook import NotebookProgressCallback\n",
    "from datasets import Dataset # HuggingFace\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import OneCycleLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d4d9e9e-81a7-4aab-8b01-4b9cbf4773db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pl.Config(fmt_str_lengths=2000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60138f6d-28db-41bf-adcb-850c260e5a22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!conda install -c conda-forge faiss-gpu -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "206053ff-2baa-487e-8226-2a0e664266e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6374, 8),\n",
       " array(['question', 'correct', 'incorrect_1', 'incorrect_2', 'incorrect_3',\n",
       "        'incorrect_4', 'title', 'section_title'], dtype='<U13'))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = []\n",
    "folder_path = './data/daniel_train/v_1/*'\n",
    "columns = ['question', 'correct', 'incorrect_1', 'incorrect_2', 'incorrect_3', 'incorrect_4', 'title', 'section_title']\n",
    "\n",
    "for csv_file in glob.glob(folder_path):\n",
    "    df = pl.read_csv(csv_file)\n",
    "    dfs.append(df[columns])\n",
    "\n",
    "train_raw = pl.concat(dfs)\\\n",
    "              .filter(pl.col('question').is_not_null())\n",
    "train_raw.shape, np.array(train_raw.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43bdc699-3447-464c-8759-8879acd67280",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_raw.write_parquet('./data/daniel_train/v_1_combined/daniel_train_v_1.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1207aec-ede1-4a80-ba91-be9048923231",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5874 500\n"
     ]
    }
   ],
   "source": [
    "choices_np = train_raw[['correct', 'incorrect_1', 'incorrect_2', 'incorrect_3', 'incorrect_4']].to_numpy()\n",
    "\n",
    "n_rows, n_cols = choices_np.shape\n",
    "shuffled_indices = np.array([np.random.permutation(n_cols) for _ in range(n_rows)])\n",
    "shuffled_data = np.take_along_axis(choices_np, shuffled_indices, axis=1)\n",
    "correct_positions = np.argmax(shuffled_data == choices_np[:, 0][:, np.newaxis], axis=1)\n",
    "\n",
    "answer_map = np.array(['A', 'B', 'C', 'D', 'E'])\n",
    "answers = answer_map[correct_positions]\n",
    "\n",
    "choices = pl.DataFrame({\n",
    "    'A': shuffled_data[:, 0].astype(str),\n",
    "    'B': shuffled_data[:, 1].astype(str),\n",
    "    'C': shuffled_data[:, 2].astype(str),\n",
    "    'D': shuffled_data[:, 3].astype(str),\n",
    "    'E': shuffled_data[:, 4].astype(str),\n",
    "    'answer': answers\n",
    "    },\n",
    "    [(col, pl.Utf8) for col in ['A', 'B', 'C', 'D', 'E', 'answer']]\n",
    ")\n",
    "\n",
    "train = train_raw[['question','title', 'section_title']].with_columns(choices)\n",
    "\n",
    "n_test2 = 500\n",
    "test2 = train[train.shape[0] - n_test2:]\n",
    "train = train[:train.shape[0] - n_test2]\n",
    "print(train.shape[0], test2.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8aa9a52-893e-49dd-8b92-fa961c50c330",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5518, 8),\n",
       " (500, 8),\n",
       " ['question', 'A', 'C', 'B', 'D', 'E', 'answer', 'wikipedia_excerpt'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_osmu = pl.read_csv('./data/6000_wiki_en_sci_questions_with_excerpts.csv') \\\n",
    "               .filter(pl.col('A').is_not_null())\n",
    "train_osmu = train_osmu.rename({'prompt': 'question'})\n",
    "\n",
    "test_osmu = train_osmu[train_osmu.shape[0]- n_test2:]\n",
    "train_osmu = train_osmu[:train_osmu.shape[0]- n_test2]\n",
    "train_osmu.shape, test_osmu.shape, train_osmu.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "803bdf2d-6242-4c72-9c92-d4f90e2f63b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['question', 'A', 'B', 'C', 'D', 'E', 'answer']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pl.read_csv('data/train.csv')\n",
    "test = test.rename({'prompt': 'question'})\n",
    "test = test.drop(columns=\"id\")\n",
    "test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4d7781-4310-4cfc-8ef3-9fc50ea3c4a4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Retrieve Wiki Context via ColBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c8f318e-ba0a-4b2e-923e-51bf0d152e74",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m max_words \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m250\u001b[39m\n\u001b[0;32m----> 2\u001b[0m wiki_passages \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mread_parquet(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./data/colbert-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_words\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-v3/wiki_passages_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_words\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.parquet\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m wiki_passages\u001b[38;5;241m.\u001b[39mcolumns\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pl' is not defined"
     ]
    }
   ],
   "source": [
    "max_words = 140\n",
    "wiki_passages = pl.read_parquet(f'./data/colbert-{max_words}-v3/wiki_passages_{max_words}.parquet')\n",
    "wiki_passages.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e420b8d-0936-4531-a8ff-be8ac44cdf1d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140, 47436)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts = wiki_passages['passage_text'].str.split(' ').list.lengths()\n",
    "assert max_words == word_counts.max()\n",
    "word_counts.max(), wiki_passages['title'].n_unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "086b8d15-7c58-4304-a61b-03ba85057199",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[6,3])\n",
    "sns.histplot(word_counts, binrange=[0, 150], bins=75)\n",
    "plt.title('Passages character length');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97bc9251-4b99-47be-bf46-02a8bb210b6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_results_per_question = 3\n",
    "\n",
    "nbits = 2   # encode each dimension with 2 bits\n",
    "doc_maxlen = 512   # lenght in tokens\n",
    "dim = 128 # 128 is max for BERT\n",
    "\n",
    "wiki_passages = pl.read_parquet(f'./data/colbert-{max_words}-v3/wiki_passages_{max_words}.parquet')\n",
    "wiki_passages.columns\n",
    "\n",
    "checkpoint = './checkpoints/colbertv2.0'\n",
    "indexer_name = f\"wiki_pages_index_{nbits}bits_max_words{max_words}\"\n",
    "#os.environ['COLBERT_LOAD_TORCH_EXTENSION_VERBOSE'] = 'True'\n",
    "\n",
    "config = ColBERTConfig(\n",
    "    doc_maxlen=doc_maxlen,\n",
    "    nbits=nbits,\n",
    "    dim=dim\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b1dff06-7d3f-49c4-ab54-1c6f6be44a61",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['question', 'title', 'section_title', 'A', 'B', 'C', 'D', 'E', 'answer']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8929ebb8-16bd-453d-bc47-175248a0a010",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_q_colbert_context(data):\n",
    "    num_ctx_cols = 2\n",
    "    queries = data.with_row_count('qid')[['qid', 'question']]\n",
    "    queries = queries.with_columns(pl.col('question').str.replace_all('\\n', ' ')) \n",
    "    queries_file = './data/wiki_queries.tsv'\n",
    "    queries.write_csv(queries_file, separator='\\t', has_header=False)\n",
    "\n",
    "    c_queries = Queries(queries_file)\n",
    "\n",
    "    with Run().context(RunConfig(nranks=1, \n",
    "                                 index_root=f'./data/colbert-{max_words}-v3')):\n",
    "        searcher = Searcher(index=indexer_name,\n",
    "                            config=config,\n",
    "                            collection=f'./data/colbert-140-v3/wiki_passages_{max_words}.tsv')\n",
    "        ranking = searcher.search_all(c_queries, k=n_results_per_question)\n",
    "\n",
    "    colbert_passage_ids = pl.DataFrame(pd.DataFrame(ranking.items()))\n",
    "    colbert_passage_ids = colbert_passage_ids \\\n",
    "        .lazy() \\\n",
    "        .select([pl.col(\"1\").list.get(i).list.get(0).alias(f\"wiki_ctx_{i+1}\").cast(pl.UInt32) for i in range(num_ctx_cols)]) \\\n",
    "        .collect()\n",
    "    \n",
    "    passages = wiki_passages[['passage_id', 'passage_text']]\n",
    "    data_p = data.with_columns(colbert_passage_ids)\n",
    "    for i in range(num_ctx_cols):\n",
    "        data_p = data_p.join(passages, how='left', left_on=f'wiki_ctx_{i+1}', right_on='passage_id', validate='m:1', suffix=f'_{i+1}')\n",
    "    return data_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ef0008d-09c3-4b9c-b858-6ff6e42fe9ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sep 10, 14:17:26] #> Loading the queries from ./data/wiki_queries.tsv ...\n",
      "[Sep 10, 14:17:26] #> Got 5874 queries. All QIDs are unique.\n",
      "\n",
      "[Sep 10, 14:17:26] #> Loading collection...\n",
      "0M \n",
      "[Sep 10, 14:17:28] #> Loading codec...\n",
      "[Sep 10, 14:17:28] Loading decompress_residuals_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
      "[Sep 10, 14:17:28] Loading packbits_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
      "[Sep 10, 14:17:28] #> Loading IVF...\n",
      "[Sep 10, 14:17:28] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:00<00:00, 3192.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sep 10, 14:17:28] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 34/34 [00:00<00:00, 35.61it/s]\n",
      "100%|██████████| 5874/5874 [00:24<00:00, 236.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sep 10, 14:17:55] #> Loading the queries from ./data/wiki_queries.tsv ...\n",
      "[Sep 10, 14:17:55] #> Got 5518 queries. All QIDs are unique.\n",
      "\n",
      "[Sep 10, 14:17:55] #> Loading collection...\n",
      "0M \n",
      "[Sep 10, 14:17:57] #> Loading codec...\n",
      "[Sep 10, 14:17:57] #> Loading IVF...\n",
      "[Sep 10, 14:17:57] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:00<00:00, 3247.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sep 10, 14:17:57] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 34/34 [00:00<00:00, 43.26it/s]\n",
      "100%|██████████| 5518/5518 [00:26<00:00, 206.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sep 10, 14:18:26] #> Loading the queries from ./data/wiki_queries.tsv ...\n",
      "[Sep 10, 14:18:26] #> Got 200 queries. All QIDs are unique.\n",
      "\n",
      "[Sep 10, 14:18:26] #> Loading collection...\n",
      "0M \n",
      "[Sep 10, 14:18:27] #> Loading codec...\n",
      "[Sep 10, 14:18:27] #> Loading IVF...\n",
      "[Sep 10, 14:18:27] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:00<00:00, 3187.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sep 10, 14:18:27] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 34/34 [00:01<00:00, 28.43it/s]\n",
      "100%|██████████| 200/200 [00:00<00:00, 215.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sep 10, 14:18:30] #> Loading the queries from ./data/wiki_queries.tsv ...\n",
      "[Sep 10, 14:18:30] #> Got 500 queries. All QIDs are unique.\n",
      "\n",
      "[Sep 10, 14:18:30] #> Loading collection...\n",
      "0M \n",
      "[Sep 10, 14:18:32] #> Loading codec...\n",
      "[Sep 10, 14:18:32] #> Loading IVF...\n",
      "[Sep 10, 14:18:32] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:00<00:00, 2853.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sep 10, 14:18:32] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 34/34 [00:00<00:00, 39.11it/s]\n",
      "100%|██████████| 500/500 [00:02<00:00, 218.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sep 10, 14:18:35] #> Loading the queries from ./data/wiki_queries.tsv ...\n",
      "[Sep 10, 14:18:35] #> Got 500 queries. All QIDs are unique.\n",
      "\n",
      "[Sep 10, 14:18:35] #> Loading collection...\n",
      "0M \n",
      "[Sep 10, 14:18:37] #> Loading codec...\n",
      "[Sep 10, 14:18:37] #> Loading IVF...\n",
      "[Sep 10, 14:18:37] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:00<00:00, 2853.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sep 10, 14:18:37] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 34/34 [00:00<00:00, 44.15it/s]\n",
      "100%|██████████| 500/500 [00:02<00:00, 194.47it/s]\n"
     ]
    }
   ],
   "source": [
    "rerun = True\n",
    "\n",
    "train_p_path = Path(f'./data/train_daniel_with_wiki_context_{nbits}bits_max_words{max_words}.parquet')\n",
    "train_osmu_p_path = Path(f'./data/train_osmu_with_wiki_context_{nbits}bits_max_words{max_words}.parquet')\n",
    "test_p_path = Path(f'./data/test_daniel_with_wiki_context_{nbits}bits_max_words{max_words}.parquet')\n",
    "test2_p_path = Path(f'./data/test2_daniel_with_wiki_context_{nbits}bits_max_words{max_words}.parquet')\n",
    "test_osmu_p_path = Path(f'./data/test2_osmu_with_wiki_context_{nbits}bits_max_words{max_words}.parquet')\n",
    "\n",
    "def cached_add_q_colbert_context(data, cache_path):\n",
    "    if cache_path.exists() and not rerun:\n",
    "        return pl.read_parquet(cache_path)\n",
    "    else:\n",
    "        with_context = add_q_colbert_context(data)\n",
    "        torch.cuda.empty_cache()\n",
    "        with_context.write_parquet(cache_path)\n",
    "        return with_context\n",
    "    \n",
    "train_p = cached_add_q_colbert_context(train, train_p_path)\n",
    "train_osmu_p = cached_add_q_colbert_context(train_osmu, train_osmu_p_path)\n",
    "test_p = cached_add_q_colbert_context(test, test_p_path)\n",
    "test2_p = cached_add_q_colbert_context(test2, test2_p_path)\n",
    "test_osmu_p = cached_add_q_colbert_context(test_osmu, test_osmu_p_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "45407120-ba68-45cc-9d45-7825d6c4d08a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_osmu_p['passage_text'].str.split(' ').list.lengths().max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f23d30-37e3-4cb6-9b19-bc929f86af41",
   "metadata": {},
   "source": [
    "## Prepare Train and Test for DeBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e24fff00-e749-4daf-82c2-a10fbf3d1ae0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/home/daniel/anaconda3/envs/pytorch/lib/python3.8/site-packages/transformers/convert_slow_tokenizer.py:470: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "deberta_v3_large = 'microsoft/deberta-v3-large'\n",
    "tokenizer = AutoTokenizer.from_pretrained(deberta_v3_large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "62ac41ab-9963-4c50-858c-3787c620073c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_length = 625\n",
    "\n",
    "option_to_index = {option: idx for idx, option in enumerate('ABCDE')}\n",
    "index_to_option = {v: k for k,v in option_to_index.items()}\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorForMultipleChoice:\n",
    "    tokenizer: PreTrainedTokenizerBase\n",
    "    padding: Union[bool, str, PaddingStrategy] = True\n",
    "    max_length: Optional[int] = None\n",
    "\n",
    "    \n",
    "    def __call__(self, input_batch):\n",
    "        # input_batch is list of samples, choices, tokens\n",
    "        additional_cols = set(input_batch[0].keys()) - set(['input_ids', 'token_type_ids', 'attention_mask', 'label'])\n",
    "        if len(additional_cols) > 0:\n",
    "            print(f'{additional_cols=}')\n",
    "        \n",
    "        label_name = None\n",
    "        if 'label' in input_batch[0].keys():\n",
    "            label_name = 'label' \n",
    "            labels = [feature.pop(label_name) for feature in input_batch]\n",
    "        batch_size = len(input_batch)\n",
    "        num_choices = len(input_batch[0]['input_ids'])\n",
    "        flattened_input = [\n",
    "            [{k: v[i] for k, v in sample.items()} for i in range(num_choices)] for sample in input_batch\n",
    "        ]\n",
    "        flattened_input = sum(flattened_input, [])\n",
    "        \n",
    "        batch = self.tokenizer.pad(\n",
    "            flattened_input,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        \n",
    "        # batch.shape = (n_samples, n_choices, n_tokens)\n",
    "        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n",
    "        if label_name is not None:\n",
    "            batch['labels'] = torch.tensor(labels, dtype=torch.int64)\n",
    "        #print(np.array(batch['input_ids']).shape)\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "59284fda-4ec7-4f75-aaae-84fa8b5e4385",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess(example):\n",
    "    # adding the wikipedia page as context for the question by adding it after a [SEP] token to the question.\n",
    "    first_sentence = [f\"\"\"{example['question']}\n",
    "[SEP]{example['passage_text']}\n",
    "[SEP]{example['passage_text_2']}\n",
    "\"\"\"] * 5\n",
    "    second_sentences = [example[option] for option in 'ABCDE']\n",
    "    tokenized_example = tokenizer(first_sentence, second_sentences, truncation='only_first', max_length=max_length)\n",
    "    if 'answer' in example.keys():\n",
    "        tokenized_example['label'] = option_to_index[example['answer']]\n",
    "    \n",
    "    return tokenized_example\n",
    "\n",
    "def tokenized_dataset(data):\n",
    "    columns_to_keep = set(['input_ids', 'token_type_ids', 'attention_mask', 'label'])\n",
    "    dataset = Dataset.from_pandas(data.to_pandas(), preserve_index=False)\n",
    "    col_to_remove = set(data.columns) - columns_to_keep\n",
    "    tokenized = dataset.map(preprocess, remove_columns=col_to_remove)\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "89748f08-ce79-483f-a60f-157d7e41e43f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22ab4c85c0e4417dbe7136b943a5cfac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5874 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a07a1d49cf540a8b15913ae582edbb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5518 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5d8a40f11604462b182dca87bbb62d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23125bae67cb42e2acfcfe01b100cedf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24d40d84080143948a30ddac5854c2cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a79da499f996421f83b0561c27d53a35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11392 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train = tokenized_dataset(train_p)\n",
    "tokenized_train_osmu = tokenized_dataset(train_osmu_p)\n",
    "tokenized_test = tokenized_dataset(test_p)\n",
    "tokenized_test2 = tokenized_dataset(test2_p)\n",
    "tokenized_test_osmu = tokenized_dataset(test_osmu_p)\n",
    "\n",
    "cols = ['question', 'A', 'B', 'C', 'D', 'E', 'answer', 'passage_text', 'passage_text_2']\n",
    "train_comb = pl.concat([\n",
    "    train_p[cols],\n",
    "    train_osmu_p[cols]\n",
    "])\n",
    "tokenized_train_comb = tokenized_dataset(train_comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f6b8390d-b1c8-4a19-9d2b-99131e0bda56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def plot_length_hist(tokenized_data):\n",
    "#     length_list = []\n",
    "#     for sample in tokenized_data['input_ids']:\n",
    "#         for option in sample:\n",
    "#             length_list.append(len(option))\n",
    "\n",
    "#     plt.figure(figsize=[6,3])\n",
    "#     pd.Series(length_list).hist(bins=100)\n",
    "    \n",
    "# plot_length_hist(tokenized_train)\n",
    "# plot_length_hist(tokenized_train_osmu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242a4727-fea3-4135-88dd-5b7e7fa0c473",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train DeBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5cd72562-8f5c-42f2-a1a4-124e38c66ac4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def precision_at_k(predictions, actuals, k=3):        \n",
    "    if isinstance(actuals, list):\n",
    "        actuals = np.array(actuals)\n",
    "        \n",
    "    found_at = np.where(predictions == actuals.reshape(-1, 1))\n",
    "    # found_at is a tuple with the array of found indices in the second position\n",
    "    score = 1 / (1 + found_at[1])\n",
    "    score[score < 1/k] = 0\n",
    "    return score\n",
    "\n",
    "def mean_avg_precision_at_k(predictions, actual, k=3):\n",
    "    n = predictions.shape[0]\n",
    "    row_precision = precision_at_k(predictions, actual)\n",
    "    return row_precision.sum()/n\n",
    "\n",
    "acc_metric = evaluate.load(\"accuracy\")\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.flip(predictions.argsort(axis=1), axis=1)\n",
    "    accuracy = acc_metric.compute(predictions=predictions[:,0], references=labels)['accuracy']\n",
    "    map_at_3 = mean_avg_precision_at_k(predictions, labels)\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'map_at_3': round(map_at_3, 3)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "29f2a1a5-1f9a-4c0a-9738-ce23c15c7f59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForMultipleChoice were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['pooler.dense.weight', 'pooler.dense.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdatadan\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/daniel/code/kaggle-science-exam/wandb/run-20230910_141943-lkjw0k35</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/datadan/huggingface/runs/lkjw0k35' target=\"_blank\">combined_colbert</a></strong> to <a href='https://wandb.ai/datadan/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/datadan/huggingface' target=\"_blank\">https://wandb.ai/datadan/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/datadan/huggingface/runs/lkjw0k35' target=\"_blank\">https://wandb.ai/datadan/huggingface/runs/lkjw0k35</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/home/daniel/anaconda3/envs/pytorch/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2436: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/home/daniel/anaconda3/envs/pytorch/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2436: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/home/daniel/anaconda3/envs/pytorch/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2436: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/home/daniel/anaconda3/envs/pytorch/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2436: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/home/daniel/anaconda3/envs/pytorch/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2436: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/home/daniel/anaconda3/envs/pytorch/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2436: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/home/daniel/anaconda3/envs/pytorch/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2436: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/home/daniel/anaconda3/envs/pytorch/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2436: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/home/daniel/anaconda3/envs/pytorch/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2436: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/home/daniel/anaconda3/envs/pytorch/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2436: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/home/daniel/anaconda3/envs/pytorch/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2436: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/home/daniel/anaconda3/envs/pytorch/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2436: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/home/daniel/anaconda3/envs/pytorch/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2436: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/home/daniel/anaconda3/envs/pytorch/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2436: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/home/daniel/anaconda3/envs/pytorch/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2436: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/home/daniel/anaconda3/envs/pytorch/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2436: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/home/daniel/anaconda3/envs/pytorch/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2436: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/home/daniel/anaconda3/envs/pytorch/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2436: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/home/daniel/anaconda3/envs/pytorch/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2436: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/home/daniel/anaconda3/envs/pytorch/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2436: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/home/daniel/anaconda3/envs/pytorch/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2436: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/home/daniel/anaconda3/envs/pytorch/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2436: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/home/daniel/anaconda3/envs/pytorch/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2436: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/home/daniel/anaconda3/envs/pytorch/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2436: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/home/daniel/anaconda3/envs/pytorch/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2436: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/home/daniel/anaconda3/envs/pytorch/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2436: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/home/daniel/anaconda3/envs/pytorch/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2436: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/home/daniel/anaconda3/envs/pytorch/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2436: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/home/daniel/anaconda3/envs/pytorch/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2436: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/home/daniel/anaconda3/envs/pytorch/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2436: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/home/daniel/anaconda3/envs/pytorch/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2436: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/home/daniel/anaconda3/envs/pytorch/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2436: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/home/daniel/anaconda3/envs/pytorch/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2436: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/home/daniel/anaconda3/envs/pytorch/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2436: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/home/daniel/anaconda3/envs/pytorch/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2436: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/home/daniel/anaconda3/envs/pytorch/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2436: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c596ec50fec4488b7344ff03a27f2b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.004 MB of 0.004 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/test_accuracy</td><td>▁▆▇█▇▇█████</td></tr><tr><td>eval/test_daniel_accuracy</td><td>▁▆▇▇███████</td></tr><tr><td>eval/test_daniel_loss</td><td>█▂▁▁▂▁▃▂▂▂▂</td></tr><tr><td>eval/test_daniel_map_at_3</td><td>▁▆▇█▇██████</td></tr><tr><td>eval/test_daniel_runtime</td><td>█▃▂▂▁▃▁▂▂▃▂</td></tr><tr><td>eval/test_daniel_samples_per_second</td><td>▁▆▇▇█▆▇▇▇▆▇</td></tr><tr><td>eval/test_daniel_steps_per_second</td><td>▁▇▇▇█▇█▇▇▆█</td></tr><tr><td>eval/test_loss</td><td>█▃▁▁▂▁▃▃▃▂▃</td></tr><tr><td>eval/test_map_at_3</td><td>▁▆▇██▇█████</td></tr><tr><td>eval/test_osmu_accuracy</td><td>▁▅▆▇▇█▇▇███</td></tr><tr><td>eval/test_osmu_loss</td><td>▂▂▃▁▅▂█▇▇▆▆</td></tr><tr><td>eval/test_osmu_map_at_3</td><td>▁▅▇▇▇█▇████</td></tr><tr><td>eval/test_osmu_runtime</td><td>▃█▆▁▃▅▅▄▆▃▅</td></tr><tr><td>eval/test_osmu_samples_per_second</td><td>▆▁▃█▆▄▄▅▃▆▄</td></tr><tr><td>eval/test_osmu_steps_per_second</td><td>▄▁▄██▄▄▄▁█▄</td></tr><tr><td>eval/test_runtime</td><td>█▂▁▁▂▂▂▁▂▁▁</td></tr><tr><td>eval/test_samples_per_second</td><td>▁▇██▇▇▇█▇██</td></tr><tr><td>eval/test_steps_per_second</td><td>▁▇██▇▇▇█▇██</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/learning_rate</td><td>▁▁▂▂▃▄▅▆▆▇███████▇▇▇▇▆▆▅▅▅▄▄▄▃▃▂▂▂▂▁▁▁▁▁</td></tr><tr><td>train/loss</td><td>█████▆▅▅▃▄▅▄▆▅▃▃▆▃▅▄▅▄▁▃▂▁▅▃▄▂▄▂▃▇▃▂▂▃▂▄</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/test_accuracy</td><td>0.84</td></tr><tr><td>eval/test_daniel_accuracy</td><td>0.87</td></tr><tr><td>eval/test_daniel_loss</td><td>0.68884</td></tr><tr><td>eval/test_daniel_map_at_3</td><td>0.917</td></tr><tr><td>eval/test_daniel_runtime</td><td>41.3462</td></tr><tr><td>eval/test_daniel_samples_per_second</td><td>12.093</td></tr><tr><td>eval/test_daniel_steps_per_second</td><td>1.524</td></tr><tr><td>eval/test_loss</td><td>0.82316</td></tr><tr><td>eval/test_map_at_3</td><td>0.898</td></tr><tr><td>eval/test_osmu_accuracy</td><td>0.592</td></tr><tr><td>eval/test_osmu_loss</td><td>2.21221</td></tr><tr><td>eval/test_osmu_map_at_3</td><td>0.72</td></tr><tr><td>eval/test_osmu_runtime</td><td>45.5922</td></tr><tr><td>eval/test_osmu_samples_per_second</td><td>10.967</td></tr><tr><td>eval/test_osmu_steps_per_second</td><td>1.382</td></tr><tr><td>eval/test_runtime</td><td>16.3822</td></tr><tr><td>eval/test_samples_per_second</td><td>12.208</td></tr><tr><td>eval/test_steps_per_second</td><td>1.526</td></tr><tr><td>train/epoch</td><td>2.0</td></tr><tr><td>train/global_step</td><td>22784</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.7701</td></tr><tr><td>train/total_flos</td><td>6.857352473119311e+16</td></tr><tr><td>train/train_loss</td><td>1.03023</td></tr><tr><td>train/train_runtime</td><td>5883.2634</td></tr><tr><td>train/train_samples_per_second</td><td>3.873</td></tr><tr><td>train/train_steps_per_second</td><td>3.873</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">combined_colbert</strong> at: <a href='https://wandb.ai/datadan/huggingface/runs/lkjw0k35' target=\"_blank\">https://wandb.ai/datadan/huggingface/runs/lkjw0k35</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230910_141943-lkjw0k35/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "retrain = True\n",
    "\n",
    "output_path = Path('./checkpoints')\n",
    "training_args = TrainingArguments(\n",
    "    learning_rate=4e-6,\n",
    "    num_train_epochs=2,\n",
    "    #fp16=True,\n",
    "    #warmup_ratio=0.5,\n",
    "    weight_decay=0.0,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=8,\n",
    "    evaluation_strategy = IntervalStrategy.STEPS,\n",
    "    logging_steps=100,\n",
    "    eval_steps=2000,\n",
    "    save_steps=5000,\n",
    "    report_to='wandb',\n",
    "    output_dir=str(output_path),\n",
    "    run_name='combined_colbert'\n",
    ")\n",
    "\n",
    "if not output_path.exists() or retrain:\n",
    "    model = AutoModelForMultipleChoice.from_pretrained(deberta_v3_large)\n",
    "    \n",
    "    # embedding_lr = 1e-8\n",
    "    # early_layers_lr = 1e-7\n",
    "    # middle_layers_lr = 1e-6\n",
    "    # late_layers_lr = 2e-5\n",
    "    # classifier_lr = 5e-5\n",
    "\n",
    "#     optimizer_grouped_parameters = [\n",
    "#         {'params': model.deberta.embeddings.parameters(), 'lr': embedding_lr},\n",
    "#         {'params': model.deberta.encoder.layer[:8].parameters(), 'lr': early_layers_lr},\n",
    "#         {'params': model.deberta.encoder.layer[8:16].parameters(), 'lr': middle_layers_lr},\n",
    "#         {'params': model.deberta.encoder.layer[16:].parameters(), 'lr': late_layers_lr},\n",
    "#         {'params': model.classifier.parameters(), 'lr': classifier_lr},\n",
    "#     ]\n",
    "    optimizer = AdamW(model.parameters(),\n",
    "                      lr=training_args.learning_rate,\n",
    "                      weight_decay=training_args.weight_decay)\n",
    "                      #optimizer_grouped_parameters)\n",
    "    \n",
    "    total_steps = len(tokenized_train_comb) // training_args.per_device_train_batch_size * training_args.num_train_epochs\n",
    "    #warmup_steps = int(total_steps * training_args.warmup_ratio)\n",
    "    #scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps, num_training_steps=total_steps)\n",
    "    scheduler = OneCycleLR(optimizer, max_lr=training_args.learning_rate, total_steps=total_steps)\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=DataCollatorForMultipleChoice(tokenizer=tokenizer, max_length=600),\n",
    "        train_dataset=tokenized_train_comb,\n",
    "        eval_dataset={\n",
    "            'test': tokenized_test,\n",
    "            'test_daniel': tokenized_test2,\n",
    "            'test_osmu': tokenized_test_osmu\n",
    "        },\n",
    "        compute_metrics=compute_metrics,\n",
    "        optimizers=(optimizer, scheduler)\n",
    "    )\n",
    "\n",
    "    # needed when there are multiple eval datasets\n",
    "    trainer.remove_callback(NotebookProgressCallback)\n",
    "    trainer.train()\n",
    "    wandb.finish()\n",
    "    trainer.save_model(output_path/training_args.run_name)\n",
    "else:\n",
    "    model = AutoModelForMultipleChoice.from_pretrained(output_path/training_args.run_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c7ffed-5442-4b18-a9b5-af19169840ee",
   "metadata": {},
   "source": [
    "## Predict Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8311360f-b360-4f5a-ac67-fa9ffd1ec40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    data_collator=DataCollatorForMultipleChoice(tokenizer=tokenizer, max_length=600),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2a5c44ec-5da4-4c04-a1c6-5a2fec5a1599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/pytorch/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2436: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def predict_testset(test_with_passages, tokenized_testset):\n",
    "    test_logits = trainer.predict(tokenized_testset).predictions\n",
    "    test_preds = np.argsort(-test_logits, 1)\n",
    "    test_letters = np.array(list('ABCDE'))[test_preds]\n",
    "    test_letters = pl.Series(test_letters[:,:3]).list.join(' ')\n",
    "\n",
    "    return test_with_passages.with_columns(all_prediction=test_letters, prediction=test_letters.str.slice(0,1))\n",
    "    \n",
    "test_pred = predict_testset(test_p, tokenized_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "95a4eecf-3187-479f-9df7-9f6449438f23",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_osmu_pred = predict_testset(test_osmu_p, tokenized_test_osmu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2c81a0c8-581f-4444-9368-f1ef3c78c984",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (0, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>passage_id</th><th>section_id</th><th>title</th><th>section_title</th><th>passage_text</th></tr><tr><td>u32</td><td>u32</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (0, 5)\n",
       "┌────────────┬────────────┬───────┬───────────────┬──────────────┐\n",
       "│ passage_id ┆ section_id ┆ title ┆ section_title ┆ passage_text │\n",
       "│ ---        ┆ ---        ┆ ---   ┆ ---           ┆ ---          │\n",
       "│ u32        ┆ u32        ┆ str   ┆ str           ┆ str          │\n",
       "╞════════════╪════════════╪═══════╪═══════════════╪══════════════╡\n",
       "└────────────┴────────────┴───────┴───────────────┴──────────────┘"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_passages.filter(pl.col('title') == 'Mycobacterium madagascariense')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc8880d-9dab-49c5-9d50-51f3de04694c",
   "metadata": {},
   "source": [
    "### Osmu data notes\n",
    "0. Based on the wikipedia_excerpt, the wrong answer is marked as correct. Wrong context is provided by Colbert.\n",
    "1. chloroformic acid and formic acid: Wrong context, though the context was in the wiki passages.\n",
    "2. interosseous muscles of the hand: context is unspecific, asnwer correct\n",
    "3. context and answer correct\n",
    "4. Star Lambda Ceti: Context missing, answer correct ----> add stars to wiki context\n",
    "5. relativistic rapidity and velocity: correct answer and context\n",
    "6. decision problem: context and answer correct\n",
    "7. trilostane in veterinary care: 2nd context and answer correct\n",
    "8. RSA cryptosystem  and nth root: context missing, answer logically inverted\n",
    "9. Mycobacterium madagascariense: context missing, wrong answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0650cbc5-54c8-4ffe-8855-4d32055a0282",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 12)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>question</th><th>A</th><th>C</th><th>B</th><th>D</th><th>E</th><th>answer</th><th>wikipedia_excerpt</th><th>passage_text</th><th>passage_text_2</th><th>all_prediction</th><th>prediction</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;What would be the consequence if an efficient method for finding the eth roots of an arbitrary number, modulo N, in an RSA cryptosystem is developed?&quot;</td><td>&quot;It would depend on the specific factors of the composite number N.&quot;</td><td>&quot;It would improve the efficiency of RSA-based cryptosystems without affecting their security.&quot;</td><td>&quot;It would increase the security of RSA-based cryptosystems, making them harder to crack.&quot;</td><td>&quot;It would have no impact on the security of RSA-based cryptosystems.&quot;</td><td>&quot;It would decrease the security of RSA-based cryptosystems, making them easier to crack.&quot;</td><td>&quot;E&quot;</td><td>&quot;RSA problem: In cryptography, the RSA problem summarizes the task of performing an RSA private-key operation given only the public key The RSA algorithm raises a message to an exponent, modulo a composite number N whose factors are not known Thus, the task can be neatly described as finding the eth roots of an arbitrary number, modulo N For large RSA key sizes (in excess of 1024 bits), no efficient method for solving this problem is known; if an efficient method is ever developed, it would threaten the current or eventual security of RSA-based cryptosystems—both for public-key encryption and digital signatures&quot;</td><td>&quot;Let SR(n) be the sum of all the mvarnth roots of unity, primitive or not. Then This is an immediate consequence of Vieta&#x27;s formulas. In fact, the mvarnth roots of unity being the roots of the polynomial Xn – 1, their sum is the coefficient of degree n – 1, which is either 1 or 0 according whether n = 1 or n &gt; 1. Alternatively, for n = 1 there is nothing to prove, and for n &gt; 1 there exists a root z ≠ 1 – since the set S of all the mvarnth roots of unity is a group (mathematics), zspacehairS = S, so the sum satisfies z SR(n) = SR(n), whence SR(n) = 0. Let SP(n) be the sum of all the primitive mvarnth roots of unity.&quot;</td><td>&quot;This algorithm works also over a field of characteristic (algebra) zero, with the only difference that it never enters in the blocks of instructions where pth roots are computed. However, in this case, Square-free polynomial#Yun&#x27;s algorithm is much more efficient because it computes the greatest common divisors of polynomials of lower degrees. A consequence is that, when factoring a polynomial over the integers, the algorithm which follows is not used: one first computes the square-free factorization over the integers, and to factor the resulting polynomials, one chooses a p such that they remain square-free modulo p.&quot;</td><td>&quot;C E B&quot;</td><td>&quot;C&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 12)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ question  ┆ A         ┆ C         ┆ B         ┆ … ┆ passage_t ┆ passage_t ┆ all_predi ┆ predicti │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ ---       ┆   ┆ ext       ┆ ext_2     ┆ ction     ┆ on       │\n",
       "│ str       ┆ str       ┆ str       ┆ str       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---      │\n",
       "│           ┆           ┆           ┆           ┆   ┆ str       ┆ str       ┆ str       ┆ str      │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ What      ┆ It would  ┆ It would  ┆ It would  ┆ … ┆ Let SR(n) ┆ This      ┆ C E B     ┆ C        │\n",
       "│ would be  ┆ depend on ┆ improve   ┆ increase  ┆   ┆ be the    ┆ algorithm ┆           ┆          │\n",
       "│ the conse ┆ the       ┆ the effic ┆ the       ┆   ┆ sum of    ┆ works     ┆           ┆          │\n",
       "│ quence if ┆ specific  ┆ iency of  ┆ security  ┆   ┆ all the   ┆ also over ┆           ┆          │\n",
       "│ an        ┆ factors   ┆ RSA-based ┆ of        ┆   ┆ mvarnth   ┆ a field   ┆           ┆          │\n",
       "│ efficient ┆ of the    ┆ cryptosys ┆ RSA-based ┆   ┆ roots of  ┆ of charac ┆           ┆          │\n",
       "│ method    ┆ composite ┆ tems      ┆ cryptosys ┆   ┆ unity,    ┆ teristic  ┆           ┆          │\n",
       "│ for       ┆ number N. ┆ without   ┆ tems,     ┆   ┆ primitive ┆ (algebra) ┆           ┆          │\n",
       "│ finding   ┆           ┆ affecting ┆ making    ┆   ┆ or not.   ┆ zero,     ┆           ┆          │\n",
       "│ the eth   ┆           ┆ their     ┆ them      ┆   ┆ Then This ┆ with the  ┆           ┆          │\n",
       "│ roots of  ┆           ┆ security. ┆ harder to ┆   ┆ is an     ┆ only diff ┆           ┆          │\n",
       "│ an        ┆           ┆           ┆ crack.    ┆   ┆ immediate ┆ erence    ┆           ┆          │\n",
       "│ arbitrary ┆           ┆           ┆           ┆   ┆ consequen ┆ that it   ┆           ┆          │\n",
       "│ number,   ┆           ┆           ┆           ┆   ┆ ce of     ┆ never     ┆           ┆          │\n",
       "│ modulo N, ┆           ┆           ┆           ┆   ┆ Vieta's   ┆ enters in ┆           ┆          │\n",
       "│ in an RSA ┆           ┆           ┆           ┆   ┆ formulas. ┆ the       ┆           ┆          │\n",
       "│ cryptosys ┆           ┆           ┆           ┆   ┆ In fact,  ┆ blocks of ┆           ┆          │\n",
       "│ tem is    ┆           ┆           ┆           ┆   ┆ the       ┆ instructi ┆           ┆          │\n",
       "│ developed ┆           ┆           ┆           ┆   ┆ mvarnth   ┆ ons where ┆           ┆          │\n",
       "│ ?         ┆           ┆           ┆           ┆   ┆ roots of  ┆ pth roots ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ unity     ┆ are       ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ being the ┆ computed. ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ roots of  ┆ However,  ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ the polyn ┆ in this   ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ omial Xn  ┆ case, Squ ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ – 1,      ┆ are-free  ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ their sum ┆ polynomia ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ is the    ┆ l#Yun's   ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ coefficie ┆ algorithm ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ nt of     ┆ is much   ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ degree n  ┆ more      ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ – 1,      ┆ efficient ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ which is  ┆ because   ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ either 1  ┆ it        ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ or 0      ┆ computes  ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ according ┆ the       ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ whether n ┆ greatest  ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ = 1 or n  ┆ common    ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ > 1. Alte ┆ divisors  ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ rnatively ┆ of polyno ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ , for n = ┆ mials of  ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ 1 there   ┆ lower     ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ is        ┆ degrees.  ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ nothing   ┆ A consequ ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ to prove, ┆ ence is   ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ and for n ┆ that,     ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ > 1 there ┆ when      ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ exists a  ┆ factoring ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ root z ≠  ┆ a polynom ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ 1 – since ┆ ial over  ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ the set S ┆ the       ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ of all    ┆ integers, ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ the       ┆ the       ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ mvarnth   ┆ algorithm ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ roots of  ┆ which     ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ unity is  ┆ follows   ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ a group   ┆ is not    ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ (mathemat ┆ used: one ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ ics), zsp ┆ first     ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ acehairS  ┆ computes  ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ = S, so   ┆ the squar ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ the sum   ┆ e-free    ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ satisfies ┆ factoriza ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ z SR(n) = ┆ tion over ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ SR(n),    ┆ the       ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ whence    ┆ integers, ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ SR(n) =   ┆ and to    ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ 0. Let    ┆ factor    ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ SP(n) be  ┆ the       ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ the sum   ┆ resulting ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ of all    ┆ polynomia ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ the       ┆ ls, one   ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ primitive ┆ chooses a ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ mvarnth   ┆ p such    ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ roots of  ┆ that they ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ unity.    ┆ remain    ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆ square-fr ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆ ee modulo ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆ p.        ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_osmu_pred[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04031842-bdfa-458e-93a7-ce6823c2faa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_output = pl.DataFrame({'prediction':test_letters}).with_row_count('id')\n",
    "# test_output.write_csv('./data/submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf74332a-ae4d-4c87-8020-781392de0ac5",
   "metadata": {},
   "source": [
    "## Check Test predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ab9ff16a-7a96-4578-ac81-4187cfc5c1cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 11)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>question</th><th>A</th><th>B</th><th>C</th><th>D</th><th>E</th><th>answer</th><th>passage_text</th><th>passage_text_2</th><th>all_prediction</th><th>prediction</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;Which of the following statements accurately describes the origin and significance of the triskeles symbol?&quot;</td><td>&quot;The triskeles symbol was reconstructed as a feminine divine triad by the rulers of Syracuse, and later adopted as an emblem. Its usage may also be related to the Greek name of Sicily, Trinacria, which means &quot;having three headlands.&quot; The head of Medusa at the center of the Sicilian triskeles represents the three headlands.&quot;</td><td>&quot;The triskeles symbol is a representation of three interlinked spirals, which was adopted as an emblem by the rulers of Syracuse. Its usage in modern flags of Sicily has its origins in the ancient Greek name for the island, Trinacria, which means &quot;Sicily with three corners.&quot; The head of Medusa at the center is a representation of the island&#x27;s rich cultural heritage.&quot;</td><td>&quot;The triskeles symbol is a representation of a triple goddess, reconstructed by the rulers of Syracuse, who adopted it as an emblem. Its significance lies in the fact that it represents the Greek name for Sicily, Trinacria, which contains the element &quot;tria,&quot; meaning three. The head of Medusa at the center of the Sicilian triskeles represents the three headlands.&quot;</td><td>&quot;The triskeles symbol represents three interlocked spiral arms, which became an emblem for the rulers of Syracuse. Its usage in modern flags of Sicily is due to the island&#x27;s rich cultural heritage, which dates back to ancient times. The head of Medusa at the center represents the lasting influence of Greek mythology on Sicilian culture.&quot;</td><td>&quot;The triskeles symbol is a representation of the Greek goddess Hecate, reconstructed by the rulers of Syracuse. Its adoption as an emblem was due to its cultural significance, as it represented the ancient Greek name for Sicily, Trinacria. The head of Medusa at the center of the Sicilian triskeles represents the island&#x27;s central location in the Mediterranean.&quot;</td><td>&quot;A&quot;</td><td>&quot;The oldest find of a triskeles in Sicily is a vase dated to 700 BCE, for which researchers assume a Minoan civilization origin. Roman period and Late Antiquity Late examples of the triple spiral symbols are found in Iron Age Europe, e.g. petroglyph in Castro Culture settlement in Galicia (Spain), Asturias and Northern Portugal. In Ireland before the 5th century, in Celtic Christianity the symbol took on new meaning, as a symbol of the Trinity (Father, Son, and Holy Spirit).&quot;</td><td>&quot;anchorSicily The triskeles was adopted as emblem by the rulers of Syracuse, Sicily. It is possible that this usage is related with the Greek name of the island of Sicily, Trinacria (Τρινακρία &#x27;having three headlands&#x27;). The Sicilian triskeles is shown with the Gorgoneion at the center. The ancient symbol has been re-introduced in modern flag of Sicily since 1848. The oldest find of a triskeles in Sicily is a vase dated to 700 BCE, for which researchers assume a Minoan civilization origin.&quot;</td><td>&quot;D A C&quot;</td><td>&quot;D&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 11)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ question  ┆ A         ┆ B         ┆ C         ┆ … ┆ passage_t ┆ passage_t ┆ all_predi ┆ predicti │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ ---       ┆   ┆ ext       ┆ ext_2     ┆ ction     ┆ on       │\n",
       "│ str       ┆ str       ┆ str       ┆ str       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---      │\n",
       "│           ┆           ┆           ┆           ┆   ┆ str       ┆ str       ┆ str       ┆ str      │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ Which of  ┆ The       ┆ The       ┆ The       ┆ … ┆ The       ┆ anchorSic ┆ D A C     ┆ D        │\n",
       "│ the       ┆ triskeles ┆ triskeles ┆ triskeles ┆   ┆ oldest    ┆ ily The   ┆           ┆          │\n",
       "│ following ┆ symbol    ┆ symbol is ┆ symbol is ┆   ┆ find of a ┆ triskeles ┆           ┆          │\n",
       "│ statement ┆ was recon ┆ a represe ┆ a represe ┆   ┆ triskeles ┆ was       ┆           ┆          │\n",
       "│ s accurat ┆ structed  ┆ ntation   ┆ ntation   ┆   ┆ in Sicily ┆ adopted   ┆           ┆          │\n",
       "│ ely       ┆ as a      ┆ of three  ┆ of a      ┆   ┆ is a vase ┆ as emblem ┆           ┆          │\n",
       "│ describes ┆ feminine  ┆ interlink ┆ triple    ┆   ┆ dated to  ┆ by the    ┆           ┆          │\n",
       "│ the       ┆ divine    ┆ ed        ┆ goddess,  ┆   ┆ 700 BCE,  ┆ rulers of ┆           ┆          │\n",
       "│ origin    ┆ triad by  ┆ spirals,  ┆ reconstru ┆   ┆ for which ┆ Syracuse, ┆           ┆          │\n",
       "│ and signi ┆ the       ┆ which was ┆ cted by   ┆   ┆ researche ┆ Sicily.   ┆           ┆          │\n",
       "│ ficance   ┆ rulers of ┆ adopted   ┆ the       ┆   ┆ rs assume ┆ It is     ┆           ┆          │\n",
       "│ of the    ┆ Syracuse, ┆ as an     ┆ rulers of ┆   ┆ a Minoan  ┆ possible  ┆           ┆          │\n",
       "│ triskeles ┆ and later ┆ emblem by ┆ Syracuse, ┆   ┆ civilizat ┆ that this ┆           ┆          │\n",
       "│ symbol?   ┆ adopted   ┆ the       ┆ who       ┆   ┆ ion       ┆ usage is  ┆           ┆          │\n",
       "│           ┆ as an     ┆ rulers of ┆ adopted   ┆   ┆ origin.   ┆ related   ┆           ┆          │\n",
       "│           ┆ emblem.   ┆ Syracuse. ┆ it as an  ┆   ┆ Roman     ┆ with the  ┆           ┆          │\n",
       "│           ┆ Its usage ┆ Its usage ┆ emblem.   ┆   ┆ period    ┆ Greek     ┆           ┆          │\n",
       "│           ┆ may also  ┆ in modern ┆ Its signi ┆   ┆ and Late  ┆ name of   ┆           ┆          │\n",
       "│           ┆ be        ┆ flags of  ┆ ficance   ┆   ┆ Antiquity ┆ the       ┆           ┆          │\n",
       "│           ┆ related   ┆ Sicily    ┆ lies in   ┆   ┆ Late      ┆ island of ┆           ┆          │\n",
       "│           ┆ to the    ┆ has its   ┆ the fact  ┆   ┆ examples  ┆ Sicily,   ┆           ┆          │\n",
       "│           ┆ Greek     ┆ origins   ┆ that it   ┆   ┆ of the    ┆ Trinacria ┆           ┆          │\n",
       "│           ┆ name of   ┆ in the    ┆ represent ┆   ┆ triple    ┆ (Τρινακρί ┆           ┆          │\n",
       "│           ┆ Sicily,   ┆ ancient   ┆ s the     ┆   ┆ spiral    ┆ α 'having ┆           ┆          │\n",
       "│           ┆ Trinacria ┆ Greek     ┆ Greek     ┆   ┆ symbols   ┆ three hea ┆           ┆          │\n",
       "│           ┆ , which   ┆ name for  ┆ name for  ┆   ┆ are found ┆ dlands'). ┆           ┆          │\n",
       "│           ┆ means     ┆ the       ┆ Sicily,   ┆   ┆ in Iron   ┆ The       ┆           ┆          │\n",
       "│           ┆ \"having   ┆ island,   ┆ Trinacria ┆   ┆ Age       ┆ Sicilian  ┆           ┆          │\n",
       "│           ┆ three hea ┆ Trinacria ┆ , which   ┆   ┆ Europe,   ┆ triskeles ┆           ┆          │\n",
       "│           ┆ dlands.\"  ┆ , which   ┆ contains  ┆   ┆ e.g. petr ┆ is shown  ┆           ┆          │\n",
       "│           ┆ The head  ┆ means     ┆ the       ┆   ┆ oglyph in ┆ with the  ┆           ┆          │\n",
       "│           ┆ of Medusa ┆ \"Sicily   ┆ element   ┆   ┆ Castro    ┆ Gorgoneio ┆           ┆          │\n",
       "│           ┆ at the    ┆ with      ┆ \"tria,\"   ┆   ┆ Culture   ┆ n at the  ┆           ┆          │\n",
       "│           ┆ center of ┆ three     ┆ meaning   ┆   ┆ settlemen ┆ center.   ┆           ┆          │\n",
       "│           ┆ the       ┆ corners.\" ┆ three.    ┆   ┆ t in      ┆ The       ┆           ┆          │\n",
       "│           ┆ Sicilian  ┆ The head  ┆ The head  ┆   ┆ Galicia   ┆ ancient   ┆           ┆          │\n",
       "│           ┆ triskeles ┆ of Medusa ┆ of Medusa ┆   ┆ (Spain),  ┆ symbol    ┆           ┆          │\n",
       "│           ┆ represent ┆ at the    ┆ at the    ┆   ┆ Asturias  ┆ has been  ┆           ┆          │\n",
       "│           ┆ s the     ┆ center is ┆ center of ┆   ┆ and       ┆ re-introd ┆           ┆          │\n",
       "│           ┆ three hea ┆ a represe ┆ the       ┆   ┆ Northern  ┆ uced in   ┆           ┆          │\n",
       "│           ┆ dlands.   ┆ ntation   ┆ Sicilian  ┆   ┆ Portugal. ┆ modern    ┆           ┆          │\n",
       "│           ┆           ┆ of the    ┆ triskeles ┆   ┆ In        ┆ flag of   ┆           ┆          │\n",
       "│           ┆           ┆ island's  ┆ represent ┆   ┆ Ireland   ┆ Sicily    ┆           ┆          │\n",
       "│           ┆           ┆ rich      ┆ s the     ┆   ┆ before    ┆ since     ┆           ┆          │\n",
       "│           ┆           ┆ cultural  ┆ three hea ┆   ┆ the 5th   ┆ 1848. The ┆           ┆          │\n",
       "│           ┆           ┆ heritage. ┆ dlands.   ┆   ┆ century,  ┆ oldest    ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ in Celtic ┆ find of a ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ Christian ┆ triskeles ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ ity the   ┆ in Sicily ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ symbol    ┆ is a vase ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ took on   ┆ dated to  ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ new       ┆ 700 BCE,  ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ meaning,  ┆ for which ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ as a      ┆ researche ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ symbol of ┆ rs assume ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ the       ┆ a Minoan  ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ Trinity   ┆ civilizat ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ (Father,  ┆ ion       ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ Son, and  ┆ origin.   ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ Holy      ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ Spirit).  ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong = test_pred#.filter(pl.col('answer') != pl.col('prediction'))\n",
    "wrong = wrong.drop(['wiki_ctx_1', 'wiki_ctx_2'])\n",
    "wrong[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8dad1b-d65d-4bea-8031-82348eb22379",
   "metadata": {},
   "source": [
    "### Check Test Log\n",
    "- The passages are often very similar or even contain duplications.\n",
    "- Sometimes information from the answers could help make the passages more relevant.\n",
    "\n",
    "\n",
    "0. Dynamic scaling: Incorrect context, picked answeres with incorrect negations before the correct answer\n",
    "1. Triskeles: Correct context, incorrect answer:  The triskeles is not exclusively an emblem for the rulers of Syracuse but rather a broader symbol related to Sicily and its Greek heritage.\n",
    "2. Regularization in terms of renomralization (physics): The context is useful, longer context might have been helpful. The answers differ in subtleties that the model does not get.\n",
    "3. Gauss law, electic flux: The model seems to miss some subtle differences. The context is missing the formula.\n",
    "4. Blocking tempereature of a spin valve: Context describes spin valves, but not the blocking temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34958330-b2be-448c-a810-95e5b22bc580",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
