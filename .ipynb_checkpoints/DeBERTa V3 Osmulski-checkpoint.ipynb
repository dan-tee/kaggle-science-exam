{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "139fdfa6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Optional, Union\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import evaluate\n",
    "import os\n",
    "from scipy.special import softmax\n",
    "\n",
    "from pathlib import Path\n",
    "import wandb\n",
    "from datasets import Dataset # HuggingFace\n",
    "from dataclasses import dataclass\n",
    "from transformers import AutoTokenizer\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n",
    "from transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer, AutoModel, IntervalStrategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02e8112e-6666-45df-aa0c-578309b69681",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "#logging.basicConfig(level=logging.DEBUG, format='%(asctime)s %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04506376-fe46-4750-8e8e-c6bb559af9e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ['WANDB_NOTEBOOK_NAME'] = 'DeBERTa V3 Osmulski.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1385d217-eec6-4afb-ae8c-9e42d52425f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec79c1af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !conda install wandb -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7b40123",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e1c680d-d26f-41ad-add6-d205c2c9ce25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "deberta_v3_large = 'microsoft/deberta-v3-large'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a60a98de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['prompt', 'A', 'B', 'C', 'D', 'E', 'answer'], dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('data/train.csv')\n",
    "df_test = df_test.drop(columns=\"id\")\n",
    "df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33962dcf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5800, 7) (200, 7) (500, 7)\n"
     ]
    }
   ],
   "source": [
    "df_6000 = pd.read_csv('data/osmulski_6000.csv')\n",
    "df_train = df_6000[:5800]\n",
    "df_test_1 = df_6000[5800:]\n",
    "df_test_2 = pd.read_csv('data/osmulski_extra_train.csv')\n",
    "print(df_train.shape, df_test_1.shape, df_test_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "264141cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "option_to_index = {option: idx for idx, option in enumerate('ABCDE')}\n",
    "index_to_option = {v: k for k,v in option_to_index.items()}\n",
    "\n",
    "def preprocess(example):\n",
    "    first_sentence = [example['prompt']] * 5\n",
    "    second_sentences = [example[option] for option in 'ABCDE']\n",
    "    tokenized_example = tokenizer(first_sentence, second_sentences, truncation=True)\n",
    "    tokenized_example['label'] = option_to_index[example['answer']]\n",
    "    \n",
    "    return tokenized_example\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorForMultipleChoice:\n",
    "    tokenizer: PreTrainedTokenizerBase\n",
    "    padding: Union[bool, str, PaddingStrategy] = True\n",
    "    max_length: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "    \n",
    "    def __call__(self, features):\n",
    "        label_name = 'label' if 'label' in features[0].keys() else 'labels'\n",
    "        labels = [feature.pop(label_name) for feature in features]\n",
    "        batch_size = len(features)\n",
    "        num_choices = len(features[0]['input_ids'])\n",
    "        flattened_features = [\n",
    "            [{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features\n",
    "        ]\n",
    "        flattened_features = sum(flattened_features, [])\n",
    "        \n",
    "        batch = self.tokenizer.pad(\n",
    "            flattened_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n",
    "        batch['labels'] = torch.tensor(labels, dtype=torch.int64)\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b6ccf20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/home/daniel/anaconda3/envs/pytorch/lib/python3.8/site-packages/transformers/convert_slow_tokenizer.py:454: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'token_type_ids', 'attention_mask', 'label'],\n",
       "    num_rows: 5800\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deberta_v3_large = 'microsoft/deberta-v3-large'\n",
    "tokenizer = AutoTokenizer.from_pretrained(deberta_v3_large)\n",
    "\n",
    "train_dataset = Dataset.from_pandas(df_train, preserve_index=False)\n",
    "tokenized_train = train_dataset.map(preprocess, remove_columns=['prompt', 'A', 'B', 'C', 'D', 'E', 'answer'])\n",
    "tokenized_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "602f4aa9-2fbe-43fd-aff3-f78babd299f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'token_type_ids', 'attention_mask', 'label'],\n",
       "    num_rows: 200\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = Dataset.from_pandas(df_test)\n",
    "tokenized_test = test_dataset.map(preprocess, remove_columns=['prompt', 'A', 'B', 'C', 'D', 'E', 'answer'])\n",
    "tokenized_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28898fcf",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "073ee6c5-f52c-43f8-831a-a8afcd46bf3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def precision_at_k(predictions, actuals, k=3):        \n",
    "    if isinstance(actuals, list):\n",
    "        actuals = np.array(actuals)\n",
    "        \n",
    "    found_at = np.where(predictions == actuals.reshape(-1, 1))\n",
    "    # found_at is a tuple with the array of found indices in the second position\n",
    "    score = 1 / (1 + found_at[1])\n",
    "    score[score < 1/k] = 0\n",
    "    return score\n",
    "\n",
    "def mean_avg_precision_at_k(predictions, actual, k=3):\n",
    "    n = predictions.shape[0]\n",
    "    row_precision = precision_at_k(predictions, actual)\n",
    "    return row_precision.sum()/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce703c71-7a03-4023-8fa4-1b54654897b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def score_random():\n",
    "    n_permutations = 200\n",
    "    n_numbers = 5 \n",
    "    # In this code, np.random.rand(n_permutations, n_numbers) generates a 2D array of random numbers.\n",
    "    # argsort(axis=1) then sorts along the second dimension (i.e., sorts each row) but instead of \n",
    "    # sorting the actual numbers, it sorts their indices, effectively creating a permutation.\n",
    "    random_predictions = np.random.rand(n_permutations, n_numbers).argsort(axis=1)\n",
    "    random_actuals = np.random.randint(0, n_numbers-1, n_permutations)\n",
    "    return mean_avg_precision_at_k(random_predictions, random_actuals)\n",
    "    \n",
    "scores = []\n",
    "for i in range(100000):\n",
    "    scores.append(score_random())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15bea069-b5b1-42fb-a67d-d1d3d110214d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(scores).hist(bins=25)\n",
    "plt.title('Scores of Random Predictions');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d3b1cec-5e3c-41f1-8803-0a411d0672da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "acc_metric = evaluate.load(\"accuracy\")\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.flip(predictions.argsort(axis=1), axis=1)\n",
    "    accuracy = acc_metric.compute(predictions=predictions[:,0], references=labels)['accuracy']\n",
    "    map_at_3 = mean_avg_precision_at_k(predictions, labels)\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'map_at_3': round(map_at_3, 3)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c95a3c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2ForMultipleChoice: ['lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.classifier.weight', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.LayerNorm.bias', 'mask_predictions.dense.bias']\n",
      "- This IS expected if you are initializing DebertaV2ForMultipleChoice from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2ForMultipleChoice from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DebertaV2ForMultipleChoice were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/daniel/anaconda3/envs/pytorch/lib/python3.8/site-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdatadan\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/daniel/code/kaggle-science-exam/wandb/run-20230807_164147-af23tet0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/datadan/huggingface/runs/af23tet0' target=\"_blank\">Train on reduced Osmulski</a></strong> to <a href='https://wandb.ai/datadan/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/datadan/huggingface' target=\"_blank\">https://wandb.ai/datadan/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/datadan/huggingface/runs/af23tet0' target=\"_blank\">https://wandb.ai/datadan/huggingface/runs/af23tet0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4350' max='4350' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4350/4350 09:22, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Map At 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.612600</td>\n",
       "      <td>1.609225</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>0.430000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.616300</td>\n",
       "      <td>1.608112</td>\n",
       "      <td>0.345000</td>\n",
       "      <td>0.514000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>1.633900</td>\n",
       "      <td>1.605333</td>\n",
       "      <td>0.435000</td>\n",
       "      <td>0.613000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.586800</td>\n",
       "      <td>1.602573</td>\n",
       "      <td>0.565000</td>\n",
       "      <td>0.704000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>1.535900</td>\n",
       "      <td>1.529727</td>\n",
       "      <td>0.570000</td>\n",
       "      <td>0.718000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.243800</td>\n",
       "      <td>1.175112</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.776000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>1.245200</td>\n",
       "      <td>1.041963</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.788000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.110300</td>\n",
       "      <td>0.987762</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.792000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>1.207200</td>\n",
       "      <td>0.973011</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.785000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.037800</td>\n",
       "      <td>0.956732</td>\n",
       "      <td>0.665000</td>\n",
       "      <td>0.786000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2750</td>\n",
       "      <td>1.207800</td>\n",
       "      <td>0.907549</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>0.797000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.818300</td>\n",
       "      <td>0.869373</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.791000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3250</td>\n",
       "      <td>1.404000</td>\n",
       "      <td>0.852403</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>0.796000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>1.177300</td>\n",
       "      <td>0.898623</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.781000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3750</td>\n",
       "      <td>0.881800</td>\n",
       "      <td>0.950321</td>\n",
       "      <td>0.635000</td>\n",
       "      <td>0.761000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.771500</td>\n",
       "      <td>0.875815</td>\n",
       "      <td>0.665000</td>\n",
       "      <td>0.779000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4250</td>\n",
       "      <td>0.883700</td>\n",
       "      <td>0.896306</td>\n",
       "      <td>0.655000</td>\n",
       "      <td>0.773000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a269b95e5f44c218434a9113473c6fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.003 MB of 0.003 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▂▄▆▆▇████████▇█▇</td></tr><tr><td>eval/loss</td><td>████▇▄▃▂▂▂▂▁▁▁▂▁▁</td></tr><tr><td>eval/map_at_3</td><td>▁▃▄▆▆█████████▇██</td></tr><tr><td>eval/runtime</td><td>▁▃▄▅▄▆▆▆▇▇▆▆▆▆█▇█</td></tr><tr><td>eval/samples_per_second</td><td>█▆▅▄▅▃▃▃▂▂▃▃▃▃▁▂▁</td></tr><tr><td>eval/steps_per_second</td><td>█▆▅▄▅▃▃▃▂▂▃▃▃▃▁▂▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/learning_rate</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇████▇▆▅▄▃▂▁</td></tr><tr><td>train/loss</td><td>███████████▇▆▆▅▅▇▄▅▅▅▇▅▃▄▄▅▃▃▁▃▄▂▃▂▃▃▄▂▃</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.655</td></tr><tr><td>eval/loss</td><td>0.89631</td></tr><tr><td>eval/map_at_3</td><td>0.773</td></tr><tr><td>eval/runtime</td><td>2.4044</td></tr><tr><td>eval/samples_per_second</td><td>83.182</td></tr><tr><td>eval/steps_per_second</td><td>8.318</td></tr><tr><td>train/epoch</td><td>3.0</td></tr><tr><td>train/global_step</td><td>4350</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.8477</td></tr><tr><td>train/total_flos</td><td>8034913607705880.0</td></tr><tr><td>train/train_loss</td><td>1.20149</td></tr><tr><td>train/train_runtime</td><td>566.2284</td></tr><tr><td>train/train_samples_per_second</td><td>30.73</td></tr><tr><td>train/train_steps_per_second</td><td>7.682</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Train on reduced Osmulski</strong> at: <a href='https://wandb.ai/datadan/huggingface/runs/af23tet0' target=\"_blank\">https://wandb.ai/datadan/huggingface/runs/af23tet0</a><br/> View job at <a href='https://wandb.ai/datadan/huggingface/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjg4NTI4NzEw/version_details/v2' target=\"_blank\">https://wandb.ai/datadan/huggingface/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjg4NTI4NzEw/version_details/v2</a><br/>Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230807_164147-af23tet0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "retrain = False\n",
    "\n",
    "output_path = Path('./checkpoints')\n",
    "training_args = TrainingArguments(\n",
    "    warmup_ratio=0.8,\n",
    "    learning_rate=5e-6,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=10,\n",
    "    evaluation_strategy = IntervalStrategy.STEPS,\n",
    "    logging_steps=10,\n",
    "    eval_steps=250,\n",
    "    num_train_epochs=3,\n",
    "    save_steps=5000,\n",
    "    report_to='wandb',\n",
    "    output_dir=str(output_path),\n",
    "    run_name='Train on reduced Osmulski'\n",
    ")\n",
    "\n",
    "if not output_path.exists() or retrain:\n",
    "    model = AutoModelForMultipleChoice.from_pretrained(deberta_v3_large)\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=DataCollatorForMultipleChoice(tokenizer=tokenizer),\n",
    "        train_dataset=tokenized_train,\n",
    "        eval_dataset=tokenized_test,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    \n",
    "    trainer.train()\n",
    "    wandb.finish()\n",
    "else:\n",
    "    model = AutoModelForMultipleChoice.from_pretrained(output_path/'checkpoint-19500')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8ac5ec",
   "metadata": {},
   "source": [
    "## Predicting on the Testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "11a90242",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.645, 'map_at_3': 0.771}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.55, 'map_at_3': 0.702}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.554, 'map_at_3': 0.701}\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(test_set):\n",
    "    tokenized_test_dataset = Dataset.from_pandas(test_set).map(preprocess, remove_columns=['prompt', 'A', 'B', 'C', 'D', 'E'])\n",
    "    test_predictions = trainer.predict(tokenized_test_dataset).predictions\n",
    "    print(compute_metrics([test_predictions, tokenized_test_dataset['label']]))\n",
    "    \n",
    "evaluate_model(df_test)\n",
    "evaluate_model(df_test_1)\n",
    "evaluate_model(df_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "84d1e74a-6365-4f84-83a0-3ade8664b72f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer_predict = trainer.predict(tokenized_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c51d41eb-3108-4d15-afa2-2f2830ffacfb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mType:\u001b[0m        ndarray\n",
       "\u001b[0;31mString form:\u001b[0m\n",
       "[[-9.81499255e-01  1.33976841e+00  1.60739362e+00  4.27693319e+00\n",
       "           6.14280045e-01]\n",
       "           [ 1.4250420 <...> 324652e+00]\n",
       "           [-1.70279473e-01 -3.30993199e+00 -1.98556447e+00 -9.87624466e-01\n",
       "           -2.38353133e+00]]\n",
       "\u001b[0;31mLength:\u001b[0m      200\n",
       "\u001b[0;31mFile:\u001b[0m        ~/anaconda3/envs/pytorch/lib/python3.8/site-packages/numpy/__init__.py\n",
       "\u001b[0;31mDocstring:\u001b[0m  \n",
       "ndarray(shape, dtype=float, buffer=None, offset=0,\n",
       "        strides=None, order=None)\n",
       "\n",
       "An array object represents a multidimensional, homogeneous array\n",
       "of fixed-size items.  An associated data-type object describes the\n",
       "format of each element in the array (its byte-order, how many bytes it\n",
       "occupies in memory, whether it is an integer, a floating point number,\n",
       "or something else, etc.)\n",
       "\n",
       "Arrays should be constructed using `array`, `zeros` or `empty` (refer\n",
       "to the See Also section below).  The parameters given here refer to\n",
       "a low-level method (`ndarray(...)`) for instantiating an array.\n",
       "\n",
       "For more information, refer to the `numpy` module and examine the\n",
       "methods and attributes of an array.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "(for the __new__ method; see Notes below)\n",
       "\n",
       "shape : tuple of ints\n",
       "    Shape of created array.\n",
       "dtype : data-type, optional\n",
       "    Any object that can be interpreted as a numpy data type.\n",
       "buffer : object exposing buffer interface, optional\n",
       "    Used to fill the array with data.\n",
       "offset : int, optional\n",
       "    Offset of array data in buffer.\n",
       "strides : tuple of ints, optional\n",
       "    Strides of data in memory.\n",
       "order : {'C', 'F'}, optional\n",
       "    Row-major (C-style) or column-major (Fortran-style) order.\n",
       "\n",
       "Attributes\n",
       "----------\n",
       "T : ndarray\n",
       "    Transpose of the array.\n",
       "data : buffer\n",
       "    The array's elements, in memory.\n",
       "dtype : dtype object\n",
       "    Describes the format of the elements in the array.\n",
       "flags : dict\n",
       "    Dictionary containing information related to memory use, e.g.,\n",
       "    'C_CONTIGUOUS', 'OWNDATA', 'WRITEABLE', etc.\n",
       "flat : numpy.flatiter object\n",
       "    Flattened version of the array as an iterator.  The iterator\n",
       "    allows assignments, e.g., ``x.flat = 3`` (See `ndarray.flat` for\n",
       "    assignment examples; TODO).\n",
       "imag : ndarray\n",
       "    Imaginary part of the array.\n",
       "real : ndarray\n",
       "    Real part of the array.\n",
       "size : int\n",
       "    Number of elements in the array.\n",
       "itemsize : int\n",
       "    The memory use of each array element in bytes.\n",
       "nbytes : int\n",
       "    The total number of bytes required to store the array data,\n",
       "    i.e., ``itemsize * size``.\n",
       "ndim : int\n",
       "    The array's number of dimensions.\n",
       "shape : tuple of ints\n",
       "    Shape of the array.\n",
       "strides : tuple of ints\n",
       "    The step-size required to move from one element to the next in\n",
       "    memory. For example, a contiguous ``(3, 4)`` array of type\n",
       "    ``int16`` in C-order has strides ``(8, 2)``.  This implies that\n",
       "    to move from element to element in memory requires jumps of 2 bytes.\n",
       "    To move from row-to-row, one needs to jump 8 bytes at a time\n",
       "    (``2 * 4``).\n",
       "ctypes : ctypes object\n",
       "    Class containing properties of the array needed for interaction\n",
       "    with ctypes.\n",
       "base : ndarray\n",
       "    If the array is a view into another array, that array is its `base`\n",
       "    (unless that array is also a view).  The `base` array is where the\n",
       "    array data is actually stored.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "array : Construct an array.\n",
       "zeros : Create an array, each element of which is zero.\n",
       "empty : Create an array, but leave its allocated memory unchanged (i.e.,\n",
       "        it contains \"garbage\").\n",
       "dtype : Create a data-type.\n",
       "numpy.typing.NDArray : An ndarray alias :term:`generic <generic type>`\n",
       "                       w.r.t. its `dtype.type <numpy.dtype.type>`.\n",
       "\n",
       "Notes\n",
       "-----\n",
       "There are two modes of creating an array using ``__new__``:\n",
       "\n",
       "1. If `buffer` is None, then only `shape`, `dtype`, and `order`\n",
       "   are used.\n",
       "2. If `buffer` is an object exposing the buffer interface, then\n",
       "   all keywords are interpreted.\n",
       "\n",
       "No ``__init__`` method is needed because the array is fully initialized\n",
       "after the ``__new__`` method.\n",
       "\n",
       "Examples\n",
       "--------\n",
       "These examples illustrate the low-level `ndarray` constructor.  Refer\n",
       "to the `See Also` section above for easier ways of constructing an\n",
       "ndarray.\n",
       "\n",
       "First mode, `buffer` is None:\n",
       "\n",
       ">>> np.ndarray(shape=(2,2), dtype=float, order='F')\n",
       "array([[0.0e+000, 0.0e+000], # random\n",
       "       [     nan, 2.5e-323]])\n",
       "\n",
       "Second mode:\n",
       "\n",
       ">>> np.ndarray((2,), buffer=np.array([1,2,3]),\n",
       "...            offset=np.int_().itemsize,\n",
       "...            dtype=int) # offset = 1*itemsize, i.e. skip first element\n",
       "array([2, 3])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer_predict.predictions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4f0840fe-6b1a-4a3f-a572-5c02ec51e72f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_test_dataset = Dataset.from_pandas(df_test).map(preprocess, remove_columns=['prompt', 'A', 'B', 'C', 'D', 'E'])\n",
    "test_logits = trainer.predict(tokenized_test_dataset).predictions\n",
    "test_probs = softmax(test_logits, axis=1)\n",
    "predictions = np.flip(test_logits.argsort(axis=1), axis=1)\n",
    "pred_1 = predictions[:, 0]\n",
    "pred_2 = predictions[:, 1]\n",
    "pred_3 = predictions[:, 2]\n",
    "\n",
    "row_indcs = np.arange(pred_1.shape[0])\n",
    "res = pd.DataFrame({\n",
    "    'pred_1': pred_1, \n",
    "    'prob_1': test_probs[row_indcs, pred_1],\n",
    "    'pred_2': pred_2, \n",
    "    'prob_2': test_probs[row_indcs, pred_2],\n",
    "    'pred_3': pred_3, \n",
    "    'prob_3': test_probs[row_indcs, pred_3],\n",
    "    'logit_sum': test_probs.sum(axis=1),\n",
    "    'prob_3_sum': test_probs[row_indcs, pred_1] + test_probs[row_indcs, pred_2] + test_probs[row_indcs, pred_3],\n",
    "    'actual': tokenized_test_dataset['label'],\n",
    "    'accurate': pred_1 == tokenized_test_dataset['label'],\n",
    "    'precision_at_3': precision_at_k(predictions, tokenized_test_dataset['label']).round(2)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "04a71d78-655f-46a8-9742-a398e9dbafc9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_1</th>\n",
       "      <th>prob_1</th>\n",
       "      <th>pred_2</th>\n",
       "      <th>prob_2</th>\n",
       "      <th>pred_3</th>\n",
       "      <th>prob_3</th>\n",
       "      <th>logit_sum</th>\n",
       "      <th>prob_3_sum</th>\n",
       "      <th>actual</th>\n",
       "      <th>accurate</th>\n",
       "      <th>precision_at_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.867177</td>\n",
       "      <td>2</td>\n",
       "      <td>0.060082</td>\n",
       "      <td>1</td>\n",
       "      <td>0.045974</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.973232</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.384794</td>\n",
       "      <td>3</td>\n",
       "      <td>0.229879</td>\n",
       "      <td>0</td>\n",
       "      <td>0.216674</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.831346</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.692946</td>\n",
       "      <td>2</td>\n",
       "      <td>0.154489</td>\n",
       "      <td>4</td>\n",
       "      <td>0.092092</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.939527</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0.350951</td>\n",
       "      <td>1</td>\n",
       "      <td>0.244707</td>\n",
       "      <td>0</td>\n",
       "      <td>0.237140</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.832798</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.345061</td>\n",
       "      <td>3</td>\n",
       "      <td>0.286901</td>\n",
       "      <td>1</td>\n",
       "      <td>0.263349</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.895311</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0.674848</td>\n",
       "      <td>2</td>\n",
       "      <td>0.183446</td>\n",
       "      <td>3</td>\n",
       "      <td>0.059358</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.917651</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0.599422</td>\n",
       "      <td>2</td>\n",
       "      <td>0.315494</td>\n",
       "      <td>1</td>\n",
       "      <td>0.076119</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.991035</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>0.540555</td>\n",
       "      <td>1</td>\n",
       "      <td>0.352013</td>\n",
       "      <td>4</td>\n",
       "      <td>0.096040</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988608</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0.509058</td>\n",
       "      <td>1</td>\n",
       "      <td>0.390489</td>\n",
       "      <td>2</td>\n",
       "      <td>0.080096</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.979643</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0.997954</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001455</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000338</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999747</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0.311665</td>\n",
       "      <td>4</td>\n",
       "      <td>0.293321</td>\n",
       "      <td>0</td>\n",
       "      <td>0.241500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.846486</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0.447903</td>\n",
       "      <td>1</td>\n",
       "      <td>0.278869</td>\n",
       "      <td>2</td>\n",
       "      <td>0.144810</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.871583</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>0.997349</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000765</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999244</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4</td>\n",
       "      <td>0.996248</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001792</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000762</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998803</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0.967386</td>\n",
       "      <td>2</td>\n",
       "      <td>0.023223</td>\n",
       "      <td>3</td>\n",
       "      <td>0.007810</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998418</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>0.478593</td>\n",
       "      <td>2</td>\n",
       "      <td>0.235248</td>\n",
       "      <td>3</td>\n",
       "      <td>0.168150</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.881990</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>0.889369</td>\n",
       "      <td>0</td>\n",
       "      <td>0.074125</td>\n",
       "      <td>1</td>\n",
       "      <td>0.032083</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.995578</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4</td>\n",
       "      <td>0.426521</td>\n",
       "      <td>0</td>\n",
       "      <td>0.263443</td>\n",
       "      <td>3</td>\n",
       "      <td>0.261408</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.951372</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3</td>\n",
       "      <td>0.457016</td>\n",
       "      <td>0</td>\n",
       "      <td>0.418056</td>\n",
       "      <td>4</td>\n",
       "      <td>0.067159</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.942232</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4</td>\n",
       "      <td>0.996525</td>\n",
       "      <td>3</td>\n",
       "      <td>0.002975</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999705</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3</td>\n",
       "      <td>0.978562</td>\n",
       "      <td>2</td>\n",
       "      <td>0.009485</td>\n",
       "      <td>1</td>\n",
       "      <td>0.008066</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.996114</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>0.298158</td>\n",
       "      <td>4</td>\n",
       "      <td>0.261631</td>\n",
       "      <td>3</td>\n",
       "      <td>0.221704</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.781493</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3</td>\n",
       "      <td>0.694618</td>\n",
       "      <td>2</td>\n",
       "      <td>0.192220</td>\n",
       "      <td>0</td>\n",
       "      <td>0.078320</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.965157</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>0.612315</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333254</td>\n",
       "      <td>3</td>\n",
       "      <td>0.036297</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.981866</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0.319313</td>\n",
       "      <td>4</td>\n",
       "      <td>0.313440</td>\n",
       "      <td>3</td>\n",
       "      <td>0.293677</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.926429</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999973</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0.513298</td>\n",
       "      <td>4</td>\n",
       "      <td>0.270580</td>\n",
       "      <td>2</td>\n",
       "      <td>0.215069</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998947</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3</td>\n",
       "      <td>0.991860</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004413</td>\n",
       "      <td>2</td>\n",
       "      <td>0.002777</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999049</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2</td>\n",
       "      <td>0.345262</td>\n",
       "      <td>0</td>\n",
       "      <td>0.251166</td>\n",
       "      <td>3</td>\n",
       "      <td>0.162558</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.758986</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1</td>\n",
       "      <td>0.948775</td>\n",
       "      <td>3</td>\n",
       "      <td>0.032165</td>\n",
       "      <td>4</td>\n",
       "      <td>0.006818</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.987758</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>4</td>\n",
       "      <td>0.969604</td>\n",
       "      <td>0</td>\n",
       "      <td>0.011620</td>\n",
       "      <td>3</td>\n",
       "      <td>0.011532</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.992756</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3</td>\n",
       "      <td>0.338083</td>\n",
       "      <td>1</td>\n",
       "      <td>0.270573</td>\n",
       "      <td>0</td>\n",
       "      <td>0.202366</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.811022</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>4</td>\n",
       "      <td>0.480130</td>\n",
       "      <td>3</td>\n",
       "      <td>0.377145</td>\n",
       "      <td>1</td>\n",
       "      <td>0.136106</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993381</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2</td>\n",
       "      <td>0.292815</td>\n",
       "      <td>1</td>\n",
       "      <td>0.283962</td>\n",
       "      <td>4</td>\n",
       "      <td>0.183530</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.760307</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>4</td>\n",
       "      <td>0.500728</td>\n",
       "      <td>3</td>\n",
       "      <td>0.408555</td>\n",
       "      <td>1</td>\n",
       "      <td>0.078549</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.987832</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>4</td>\n",
       "      <td>0.416513</td>\n",
       "      <td>0</td>\n",
       "      <td>0.186835</td>\n",
       "      <td>1</td>\n",
       "      <td>0.164088</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.767437</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0</td>\n",
       "      <td>0.951308</td>\n",
       "      <td>3</td>\n",
       "      <td>0.041580</td>\n",
       "      <td>2</td>\n",
       "      <td>0.006876</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999765</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>4</td>\n",
       "      <td>0.809734</td>\n",
       "      <td>3</td>\n",
       "      <td>0.189950</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999934</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2</td>\n",
       "      <td>0.557977</td>\n",
       "      <td>0</td>\n",
       "      <td>0.245381</td>\n",
       "      <td>4</td>\n",
       "      <td>0.136614</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.939972</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    pred_1    prob_1  pred_2    prob_2  pred_3    prob_3  logit_sum  \\\n",
       "0        3  0.867177       2  0.060082       1  0.045974        1.0   \n",
       "1        2  0.384794       3  0.229879       0  0.216674        1.0   \n",
       "2        0  0.692946       2  0.154489       4  0.092092        1.0   \n",
       "3        2  0.350951       1  0.244707       0  0.237140        1.0   \n",
       "4        0  0.345061       3  0.286901       1  0.263349        1.0   \n",
       "5        1  0.674848       2  0.183446       3  0.059358        1.0   \n",
       "6        0  0.599422       2  0.315494       1  0.076119        1.0   \n",
       "7        3  0.540555       1  0.352013       4  0.096040        1.0   \n",
       "8        0  0.509058       1  0.390489       2  0.080096        1.0   \n",
       "9        0  0.997954       1  0.001455       4  0.000338        1.0   \n",
       "10       1  0.311665       4  0.293321       0  0.241500        1.0   \n",
       "11       0  0.447903       1  0.278869       2  0.144810        1.0   \n",
       "12       2  0.997349       4  0.001130       1  0.000765        1.0   \n",
       "13       4  0.996248       3  0.001792       2  0.000762        1.0   \n",
       "14       1  0.967386       2  0.023223       3  0.007810        1.0   \n",
       "15       1  0.478593       2  0.235248       3  0.168150        1.0   \n",
       "16       2  0.889369       0  0.074125       1  0.032083        1.0   \n",
       "17       4  0.426521       0  0.263443       3  0.261408        1.0   \n",
       "18       3  0.457016       0  0.418056       4  0.067159        1.0   \n",
       "19       4  0.996525       3  0.002975       1  0.000205        1.0   \n",
       "20       3  0.978562       2  0.009485       1  0.008066        1.0   \n",
       "21       1  0.298158       4  0.261631       3  0.221704        1.0   \n",
       "22       3  0.694618       2  0.192220       0  0.078320        1.0   \n",
       "23       2  0.612315       1  0.333254       3  0.036297        1.0   \n",
       "24       0  0.319313       4  0.313440       3  0.293677        1.0   \n",
       "25       4  0.999945       1  0.000014       3  0.000014        1.0   \n",
       "26       0  0.513298       4  0.270580       2  0.215069        1.0   \n",
       "27       3  0.991860       0  0.004413       2  0.002777        1.0   \n",
       "28       2  0.345262       0  0.251166       3  0.162558        1.0   \n",
       "29       2  0.999991       1  0.000005       4  0.000001        1.0   \n",
       "30       1  0.948775       3  0.032165       4  0.006818        1.0   \n",
       "31       4  0.969604       0  0.011620       3  0.011532        1.0   \n",
       "32       3  0.338083       1  0.270573       0  0.202366        1.0   \n",
       "33       4  0.480130       3  0.377145       1  0.136106        1.0   \n",
       "34       2  0.292815       1  0.283962       4  0.183530        1.0   \n",
       "35       4  0.500728       3  0.408555       1  0.078549        1.0   \n",
       "36       4  0.416513       0  0.186835       1  0.164088        1.0   \n",
       "37       0  0.951308       3  0.041580       2  0.006876        1.0   \n",
       "38       4  0.809734       3  0.189950       1  0.000250        1.0   \n",
       "39       2  0.557977       0  0.245381       4  0.136614        1.0   \n",
       "\n",
       "    prob_3_sum  actual  accurate  precision_at_3  \n",
       "0     0.973232       3      True            1.00  \n",
       "1     0.831346       0     False            0.33  \n",
       "2     0.939527       0      True            1.00  \n",
       "3     0.832798       2      True            1.00  \n",
       "4     0.895311       3     False            0.50  \n",
       "5     0.917651       1      True            1.00  \n",
       "6     0.991035       0      True            1.00  \n",
       "7     0.988608       3      True            1.00  \n",
       "8     0.979643       2     False            0.33  \n",
       "9     0.999747       0      True            1.00  \n",
       "10    0.846486       4     False            0.50  \n",
       "11    0.871583       0      True            1.00  \n",
       "12    0.999244       2      True            1.00  \n",
       "13    0.998803       3     False            0.50  \n",
       "14    0.998418       1      True            1.00  \n",
       "15    0.881990       1      True            1.00  \n",
       "16    0.995578       4     False            0.00  \n",
       "17    0.951372       4      True            1.00  \n",
       "18    0.942232       0     False            0.50  \n",
       "19    0.999705       4      True            1.00  \n",
       "20    0.996114       3      True            1.00  \n",
       "21    0.781493       3     False            0.33  \n",
       "22    0.965157       2     False            0.50  \n",
       "23    0.981866       2      True            1.00  \n",
       "24    0.926429       4     False            0.50  \n",
       "25    0.999973       4      True            1.00  \n",
       "26    0.998947       0      True            1.00  \n",
       "27    0.999049       3      True            1.00  \n",
       "28    0.758986       4     False            0.00  \n",
       "29    0.999997       2      True            1.00  \n",
       "30    0.987758       1      True            1.00  \n",
       "31    0.992756       4      True            1.00  \n",
       "32    0.811022       4     False            0.00  \n",
       "33    0.993381       3     False            0.50  \n",
       "34    0.760307       2      True            1.00  \n",
       "35    0.987832       1     False            0.33  \n",
       "36    0.767437       4      True            1.00  \n",
       "37    0.999765       0      True            1.00  \n",
       "38    0.999934       4      True            1.00  \n",
       "39    0.939972       4     False            0.33  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0b89c75e-68d4-4350-8d43-57e9d43a4f72",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.00    129\n",
       "0.50     39\n",
       "0.33     17\n",
       "0.00     15\n",
       "Name: precision_at_3, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['precision_at_3'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9f2c8820-1c49-4084-a52e-235a3dcdc6a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAicAAAGdCAYAAADJ6dNTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAiBUlEQVR4nO3de3BU9f3/8dcmLAtBggKFJCVI6g0lFS1oB0Ub1IRSRGhH2opFxtuIApbiWEDrl0VFLp2hOFBvbQedsQE7oyBTL7Ct3CxiCYSKOmJhuAkyDIFJgNRlST6/P/hlMSRgDjnHfWfzfMzsxD179pz3vnJ28/Jkw4acc04AAABGZKR6AAAAgK+jnAAAAFMoJwAAwBTKCQAAMIVyAgAATKGcAAAAUygnAADAFMoJAAAwpU2qBzhdbW2t9u3bp44dOyoUCqV6HAAA0ATOOR05ckR5eXnKyGjeuQ9z5WTfvn3Kz89P9RgAAOAc7NmzRz169GjWNsyVk44dO0o6+eCys7NTPE1DiURCK1asUElJicLhcKrHMY+8vCEvb8jLG/Lyhry8OXTokAoKCpI/x5vDXDmp+1VOdna22XKSlZWl7OxsDtYmIC9vyMsb8vKGvLwhL28SiYQk+fKWDN4QCwAATKGcAAAAUygnAADAFMoJAAAwhXICAABMoZwAAABTKCcAAMAUygkAADCFcgIAAEyhnAAAAFMoJwAAwBTKCQAAMIVyAgAATKGcAAAAU9qkegAANvWa8lYg2905a2gg2wWQPjhzAgAATKGcAAAAUygnAADAFMoJAAAwhXICAABMoZwAAABTKCcAAMAUygkAADCFcgIAAEyhnAAAAFMoJwAAwBTKCQAAMIVyAgAATKGcAAAAUygnAADAFMoJAAAwhXICAABMoZwAAABTKCcAAMAUz+VkzZo1GjZsmPLy8hQKhbR06dIzrvvAAw8oFApp3rx5zRgRAAC0Jp7LybFjx9S3b18tWLDgrOstXbpUH374ofLy8s55OAAA0Pq08XqHIUOGaMiQIWddZ+/evRo/fryWL1+uoUOHnvNwAACg9fFcTr5JbW2tRo8erUcffVR9+vT5xvXj8bji8XjyelVVlSQpkUgokUj4PV6z1c1kcTaLyMsbS3lFMl0g2/XzsVnKqyUgL2/Iyxs/c/K9nMyePVtt2rTRww8/3KT1Z86cqenTpzdYvmLFCmVlZfk9nm9isViqR2hRyMsbC3nNuTaY7b799tu+b9NCXi0JeXlDXk1TXV3t27Z8LScbN27Us88+q02bNikUCjXpPlOnTtWkSZOS16uqqpSfn6+SkhJlZ2f7OZ4vEomEYrGYiouLFQ6HUz2OeS0pr8Lo8sC2/XF0cJPWs5RXUHk0NYumsJRXS0Be3pCXNxUVFb5ty9dysnbtWh04cEA9e/ZMLqupqdEjjzyiefPmaefOnQ3uE4lEFIlEGiwPh8OmDwbr81nTEvKK1zStUJ8Lr4/dQl5B5RHE47KQV0tCXt6QV9P4mZGv5WT06NG65ZZb6i0bPHiwRo8erbvvvtvPXQEAgDTluZwcPXpU27ZtS17fsWOHNm/erM6dO6tnz57q0qVLvfXD4bBycnJ02WWXNX9aAACQ9jyXk7KyMg0aNCh5ve79ImPGjNHLL7/s22AAAKB18lxOioqK5FzT/8SwsfeZAAAAnAmfrQMAAEyhnAAAAFMoJwAAwBTKCQAAMIVyAgAATKGcAAAAUygnAADAFMoJAAAwhXICAABMoZwAAABTKCcAAMAUygkAADCFcgIAAEyhnAAAAFMoJwAAwBTKCQAAMIVyAgAATKGcAAAAUygnAADAFMoJAAAwhXICAABMoZwAAABTKCcAAMAUygkAADCFcgIAAEyhnAAAAFMoJwAAwBTKCQAAMIVyAgAATKGcAAAAUygnAADAFMoJAAAwhXICAABMoZwAAABTKCcAAMAUygkAADDFczlZs2aNhg0bpry8PIVCIS1dujR5WyKR0OTJk/X9739fHTp0UF5enu666y7t27fPz5kBAEAa81xOjh07pr59+2rBggUNbquurtamTZv0xBNPaNOmTXrjjTf0+eef67bbbvNlWAAAkP7aeL3DkCFDNGTIkEZv69Spk2KxWL1l8+fP17XXXqvdu3erZ8+e5zYlAABoNTyXE68qKysVCoV0/vnnN3p7PB5XPB5PXq+qqpJ08ldEiUQi6PE8q5vJ4mwWtaS8IpkusG039fFbyiuoPPx8bJbyagnIyxvy8sbPnELOuXN+BQqFQlqyZIlGjBjR6O1fffWVBg4cqN69e+vVV19tdJ1oNKrp06c3WF5aWqqsrKxzHQ0AAHyLqqurNWrUKFVWVio7O7tZ2wqsnCQSCY0cOVK7d+/WqlWrzjhoY2dO8vPzdfDgwWY/uCAkEgnFYjEVFxcrHA6nehzzWlJehdHlgW374+jgJq1nKa+g8mhqFk1hKa+WgLy8IS9vKioqlJub60s5CeTXOolEQj//+c+1Y8cOvffee2cdMhKJKBKJNFgeDodNHwzW57OmJeQVrwkFtm2vj91CXkHlEcTjspBXS0Je3pBX0/iZke/lpK6Y/Pe//9XKlSvVpUsXv3cBAADSmOdycvToUW3bti15fceOHdq8ebM6d+6svLw83X777dq0aZP+/ve/q6amRvv375ckde7cWW3btvVvcgAAkJY8l5OysjINGjQoeX3SpEmSpDFjxigajWrZsmWSpKuuuqre/VauXKmioqJznxQAALQKnstJUVGRzvYe2ma8vxYAAIDP1gEAALZQTgAAgCmUEwAAYArlBAAAmEI5AQAAplBOAACAKZQTAABgCuUEAACYQjkBAACmUE4AAIAplBMAAGAK5QQAAJhCOQEAAKZQTgAAgCmUEwAAYArlBAAAmNIm1QMAOHe9pryV6hEAwHecOQEAAKZQTgAAgCmUEwAAYArlBAAAmEI5AQAAplBOAACAKZQTAABgCuUEAACYQjkBAACmUE4AAIAplBMAAGAK5QQAAJhCOQEAAKZQTgAAgCmUEwAAYArlBAAAmEI5AQAAplBOAACAKZ7LyZo1azRs2DDl5eUpFApp6dKl9W53zikajSovL0/t27dXUVGRPvnkE7/mBQAAac5zOTl27Jj69u2rBQsWNHr7nDlzNHfuXC1YsEAbNmxQTk6OiouLdeTIkWYPCwAA0l8br3cYMmSIhgwZ0uhtzjnNmzdPjz/+uH72s59Jkl555RV1795dpaWleuCBB5o3LQAASHu+vudkx44d2r9/v0pKSpLLIpGIfvSjH2ndunV+7goAAKQpz2dOzmb//v2SpO7du9db3r17d+3atavR+8TjccXj8eT1qqoqSVIikVAikfBzPF/UzWRxNotaUl6RTBfYtpv6+L3mFeTMQfHzWGhJx5cF5OUNeXnjZ04h59w5v7qFQiEtWbJEI0aMkCStW7dO119/vfbt26fc3Nzkevfff7/27Nmjd999t8E2otGopk+f3mB5aWmpsrKyznU0AADwLaqurtaoUaNUWVmp7OzsZm3L1zMnOTk5kk6eQfl6OTlw4ECDsyl1pk6dqkmTJiWvV1VVKT8/XyUlJc1+cEFIJBKKxWIqLi5WOBxO9TjmtaS8CqPLA9v2x9HBTVrPa15BztwSRDKcnupfqyfKMhSvDTU559aqJT0fLSAvbyoqKnzblq/lpKCgQDk5OYrFYrr66qslScePH9fq1as1e/bsRu8TiUQUiUQaLA+Hw6YPBuvzWdMS8orXhALbttfH3tS8gpy5JYnXhhSvCZk/xqxoCc9HS8irafzMyHM5OXr0qLZt25a8vmPHDm3evFmdO3dWz549NXHiRD3zzDO65JJLdMkll+iZZ55RVlaWRo0a5dvQAAAgfXkuJ2VlZRo0aFDyet2vZMaMGaOXX35Zv/3tb/W///1PDz30kA4fPqwf/vCHWrFihTp27Ojf1AAAIG15LidFRUU623toQ6GQotGootFoc+YCAACtFJ+tAwAATKGcAAAAUygnAADAFMoJAAAwhXICAABMoZwAAABTKCcAAMAUygkAADCFcgIAAEyhnAAAAFMoJwAAwBTKCQAAMIVyAgAATKGcAAAAUygnAADAFMoJAAAwhXICAABMaZPqAZCeek15S5IUyXSac61UGF2ueE0oxVMB9tQ9V4Kwc9bQwLYNBIkzJwAAwBTKCQAAMIVyAgAATKGcAAAAUygnAADAFMoJAAAwhXICAABMoZwAAABTKCcAAMAUygkAADCFcgIAAEyhnAAAAFMoJwAAwBTKCQAAMIVyAgAATKGcAAAAUygnAADAFMoJAAAwxfdycuLECf3ud79TQUGB2rdvr+9973t68sknVVtb6/euAABAGmrj9wZnz56tF154Qa+88or69OmjsrIy3X333erUqZN+/etf+707AACQZnwvJx988IGGDx+uoUOHSpJ69eqlRYsWqayszO9dAQCANOT7r3UGDhyof/7zn/r8888lSf/5z3/0/vvv6yc/+YnfuwIAAGnI9zMnkydPVmVlpXr37q3MzEzV1NRoxowZuuOOOxpdPx6PKx6PJ69XVVVJkhKJhBKJhN/jNVvdTBZnsySS6U5+zaj/tbVq6vHi9fiqy7m1Ov34aonPyyC/h6fnweuXN+TljZ85hZxzvj4zFi9erEcffVS///3v1adPH23evFkTJ07U3LlzNWbMmAbrR6NRTZ8+vcHy0tJSZWVl+TkaAAAISHV1tUaNGqXKykplZ2c3a1u+l5P8/HxNmTJF48aNSy57+umn9eqrr+qzzz5rsH5jZ07y8/N18ODBZj+4ICQSCcViMRUXFyscDqd6HLMKo8slnfw/2qf61+qJsgzFa0Mpnip1Po4ObtJ6Xo+vupxbq9OPr6bmbEmQ38PT8+D1yxvy8qaiokK5ubm+lBPff61TXV2tjIz6b2XJzMw8458SRyIRRSKRBsvD4bDpg8H6fKkWr6lfROK1oQbLWhOvx0pTj6/WnOnX1R1fLfE5GeT38Ex58PrlDXk1jZ8Z+V5Ohg0bphkzZqhnz57q06ePysvLNXfuXN1zzz1+7woAAKQh38vJ/Pnz9cQTT+ihhx7SgQMHlJeXpwceeED/93//5/euAABAGvK9nHTs2FHz5s3TvHnz/N40AABoBfhsHQAAYArlBAAAmEI5AQAAplBOAACAKZQTAABgCuUEAACYQjkBAACmUE4AAIAplBMAAGAK5QQAAJhCOQEAAKZQTgAAgCmUEwAAYArlBAAAmEI5AQAAplBOAACAKZQTAABgSptUDwAALUGvKW+legTPTp85kuk051qpMLpc8ZrQOW9356yhzR0NOCvOnAAAAFMoJwAAwBTKCQAAMIVyAgAATKGcAAAAUygnAADAFMoJAAAwhXICAABMoZwAAABTKCcAAMAUygkAADCFcgIAAEyhnAAAAFMoJwAAwBTKCQAAMIVyAgAATKGcAAAAUygnAADAlEDKyd69e/WrX/1KXbp0UVZWlq666ipt3LgxiF0BAIA008bvDR4+fFjXX3+9Bg0apHfeeUfdunXT9u3bdf755/u9KwAAkIZ8LyezZ89Wfn6+Fi5cmFzWq1cvv3cDAADSlO/lZNmyZRo8eLBGjhyp1atX67vf/a4eeugh3X///Y2uH4/HFY/Hk9erqqokSYlEQolEwu/xmq1uJouzWRLJdCe/ZtT/2lo19XjxenzV5dxanX58Bfm8TIes/Xo+tpbXP17vvfEzp5BzztdnXLt27SRJkyZN0siRI/Xvf/9bEydO1Isvvqi77rqrwfrRaFTTp09vsLy0tFRZWVl+jgYAAAJSXV2tUaNGqbKyUtnZ2c3alu/lpG3bturfv7/WrVuXXPbwww9rw4YN+uCDDxqs39iZk/z8fB08eLDZDy4IiURCsVhMxcXFCofD9W4rjC4PZJ8fRwcHst0g1WURyXB6qn+tnijLULw2lOKp7CMvb07PK8jnSlDP72+TX8dXS35N8qKpebXEPIJQUVGh3NxcX8qJ77/Wyc3N1RVXXFFv2eWXX67XX3+90fUjkYgikUiD5eFwuMEPf0samy9eE8wPE8s5nMnpWcRrQ4Hlk47Iy5u6vIJ8rqTT96O5x1c6vCZ5uu835NUS8wiCnzn4/qfE119/vbZu3Vpv2eeff64LL7zQ710BAIA05Hs5+c1vfqP169frmWee0bZt21RaWqqXXnpJ48aN83tXAAAgDfleTq655hotWbJEixYtUmFhoZ566inNmzdPd955p9+7AgAAacj395xI0q233qpbb701iE0DAIA0x2frAAAAUygnAADAFMoJAAAwhXICAABMoZwAAABTKCcAAMAUygkAADCFcgIAAEyhnAAAAFMoJwAAwBTKCQAAMIVyAgAATKGcAAAAUygnAADAFMoJAAAwhXICAABMoZwAAABT2qR6AKRWrylvpXoEAADq4cwJAAAwhXICAABMoZwAAABTKCcAAMAUygkAADCFcgIAAEyhnAAAAFMoJwAAwBTKCQAAMIVyAgAATKGcAAAAUygnAADAFMoJAAAwhXICAABMoZwAAABTKCcAAMAUygkAADCFcgIAAEwJvJzMnDlToVBIEydODHpXAAAgDQRaTjZs2KCXXnpJV155ZZC7AQAAaSSwcnL06FHdeeed+tOf/qQLLrggqN0AAIA00yaoDY8bN05Dhw7VLbfcoqeffvqM68XjccXj8eT1qqoqSVIikVAikQhqvHNWN1Njs0UyXaD7DEJQMye3n+HqfcXZkZc3p+fVkp8r3wa/ji+Lr83f5Fy+f03NqyXmEQQ/cwg553x/xi1evFgzZszQhg0b1K5dOxUVFemqq67SvHnzGqwbjUY1ffr0BstLS0uVlZXl92gAACAA1dXVGjVqlCorK5Wdnd2sbfleTvbs2aP+/ftrxYoV6tu3rySdtZw0duYkPz9fBw8ebPaDC0IikVAsFlNxcbHC4XC92wqjywPZ58fRwYFsVwpu5jqRDKen+tfqibIMxWtDge4rHZCXN+TljV95teTXJC+amleQebQkFRUVys3N9aWc+P5rnY0bN+rAgQPq169fcllNTY3WrFmjBQsWKB6PKzMzM3lbJBJRJBJpsJ1wONzgh78ljc0XrwnmxTHIHIKaucF+akPf2r7SAXl5Q17eNDevdHhN8uKb8rL8s+rb5GcOvpeTm2++WVu2bKm37O6771bv3r01efLkesUEAADgdL6Xk44dO6qwsLDesg4dOqhLly4NlgMAAJyOfyEWAACYEtifEn/dqlWrvo3dAACANMCZEwAAYArlBAAAmEI5AQAAplBOAACAKZQTAABgCuUEAACYQjkBAACmUE4AAIAplBMAAGAK5QQAAJhCOQEAAKZQTgAAgCmUEwAAYArlBAAAmEI5AQAAplBOAACAKZQTAABgCuUEAACYQjkBAACmUE4AAIAplBMAAGAK5QQAAJhCOQEAAKZQTgAAgCmUEwAAYArlBAAAmEI5AQAAplBOAACAKZQTAABgCuUEAACYQjkBAACmUE4AAIAplBMAAGAK5QQAAJhCOQEAAKZQTgAAgCm+l5OZM2fqmmuuUceOHdWtWzeNGDFCW7du9Xs3AAAgTfleTlavXq1x48Zp/fr1isViOnHihEpKSnTs2DG/dwUAANJQG783+O6779a7vnDhQnXr1k0bN27UjTfe6PfuAABAmvG9nJyusrJSktS5c+dGb4/H44rH48nrVVVVkqREIqFEIhH0eJ7VzdTYbJFMF+g+gxDUzMntZ7h6X3F25OUNeXnjV14t+TXJi6bmZfFnVSr4mUPIORfYkeCc0/Dhw3X48GGtXbu20XWi0aimT5/eYHlpaamysrKCGg0AAPiourpao0aNUmVlpbKzs5u1rUDLybhx4/TWW2/p/fffV48ePRpdp7EzJ/n5+Tp48GCzH1wQEomEYrGYiouLFQ6H691WGF2eoqnsimQ4PdW/Vk+UZSheG0r1OOaRlzfk5Q15edPUvD6ODg5k/0H+TAli5oqKCuXm5vpSTgL7tc6ECRO0bNkyrVmz5ozFRJIikYgikUiD5eFwuMEPf0samy9ew5P9TOK1IfLxgLy8IS9vyMubb8orqJ9VQX6PgpjZz236Xk6cc5owYYKWLFmiVatWqaCgwO9dAACANOZ7ORk3bpxKS0v15ptvqmPHjtq/f78kqVOnTmrfvr3fuwMAAGnG93/n5Pnnn1dlZaWKioqUm5ubvLz22mt+7woAAKShQH6tAwAAcK74bB0AAGAK5QQAAJhCOQEAAKZQTgAAgCmUEwAAYArlBAAAmEI5AQAAplBOAACAKZQTAABgCuUEAACYQjkBAACmUE4AAIAplBMAAGAK5QQAAJhCOQEAAKZQTgAAgCmUEwAAYEqbVA/wbes15a1m3T+S6TTnWqkwulzxmpBPUwEAgDqcOQEAAKZQTgAAgCmUEwAAYArlBAAAmEI5AQAAplBOAACAKZQTAABgCuUEAACYQjkBAACmUE4AAIAplBMAAGAK5QQAAJhCOQEAAKZQTgAAgCmUEwAAYArlBAAAmEI5AQAAplBOAACAKYGVk+eee04FBQVq166d+vXrp7Vr1wa1KwAAkEYCKSevvfaaJk6cqMcff1zl5eW64YYbNGTIEO3evTuI3QEAgDQSSDmZO3eu7r33Xt133326/PLLNW/ePOXn5+v5558PYncAACCNtPF7g8ePH9fGjRs1ZcqUestLSkq0bt26BuvH43HF4/Hk9crKSknSoUOHlEgk/B5PbU4ca979a52qq2vVJpGhmtqQT1OlL/Lyhry8IS9vyMubpuZVUVERzP6b+fPqbIKY+dChQ5Ik51zzN+Z8tnfvXifJ/etf/6q3fMaMGe7SSy9tsP60adOcJC5cuHDhwoVLGly2b9/e7C7h+5mTOqFQ/ZbpnGuwTJKmTp2qSZMmJa/X1tbq0KFD6tKlS6Prp1pVVZXy8/O1Z88eZWdnp3oc88jLG/Lyhry8IS9vyMubyspK9ezZU507d272tnwvJ127dlVmZqb2799fb/mBAwfUvXv3ButHIhFFIpF6y84//3y/x/JddnY2B6sH5OUNeXlDXt6Qlzfk5U1GRvPfzur7G2Lbtm2rfv36KRaL1Vsei8V03XXX+b07AACQZgL5tc6kSZM0evRo9e/fXwMGDNBLL72k3bt3a+zYsUHsDgAApJFAyskvfvELVVRU6Mknn9SXX36pwsJCvf3227rwwguD2N23KhKJaNq0aQ1+FYXGkZc35OUNeXlDXt6Qlzd+5hVyzo+/+QEAAPAHn60DAABMoZwAAABTKCcAAMAUygkAADCFcuLBbbfdpp49e6pdu3bKzc3V6NGjtW/fvnrr7N69W8OGDVOHDh3UtWtXPfzwwzp+/HiKJk6dnTt36t5771VBQYHat2+viy66SNOmTWuQBXmdMmPGDF133XXKyso64z9ESF6nPPfccyooKFC7du3Ur18/rV27NtUjmbBmzRoNGzZMeXl5CoVCWrp0ab3bnXOKRqPKy8tT+/btVVRUpE8++SQ1wxowc+ZMXXPNNerYsaO6deumESNGaOvWrfXWIbNTnn/+eV155ZXJf5huwIABeuedd5K3+5UV5cSDQYMG6W9/+5u2bt2q119/Xdu3b9ftt9+evL2mpkZDhw7VsWPH9P7772vx4sV6/fXX9cgjj6Rw6tT47LPPVFtbqxdffFGffPKJ/vCHP+iFF17QY489llyHvOo7fvy4Ro4cqQcffLDR28nrlNdee00TJ07U448/rvLyct1www0aMmSIdu/enerRUu7YsWPq27evFixY0Ojtc+bM0dy5c7VgwQJt2LBBOTk5Ki4u1pEjR77lSW1YvXq1xo0bp/Xr1ysWi+nEiRMqKSnRsWOnPnSPzE7p0aOHZs2apbKyMpWVlemmm27S8OHDkwXEt6ya/ek8rdibb77pQqGQO378uHPOubfffttlZGS4vXv3JtdZtGiRi0QirrKyMlVjmjFnzhxXUFCQvE5ejVu4cKHr1KlTg+Xkdcq1117rxo4dW29Z79693ZQpU1I0kU2S3JIlS5LXa2trXU5Ojps1a1Zy2VdffeU6derkXnjhhRRMaM+BAwecJLd69WrnHJk1xQUXXOD+/Oc/+5oVZ07O0aFDh/TXv/5V1113ncLhsCTpgw8+UGFhofLy8pLrDR48WPF4XBs3bkzVqGZUVlbW+0Ao8vKGvE46fvy4Nm7cqJKSknrLS0pKtG7duhRN1TLs2LFD+/fvr5ddJBLRj370I7L7/yorKyUp+VpFZmdWU1OjxYsX69ixYxowYICvWVFOPJo8ebI6dOigLl26aPfu3XrzzTeTt+3fv7/BhxtecMEFatu2bYMPQmxttm/frvnz59f7CAPy8oa8Tjp48KBqamoaZNG9e/dWlcO5qMuH7BrnnNOkSZM0cOBAFRYWSiKzxmzZskXnnXeeIpGIxo4dqyVLluiKK67wNatWX06i0ahCodBZL2VlZcn1H330UZWXl2vFihXKzMzUXXfdJfe1f2Q3FAo12IdzrtHlLZHXvCRp3759+vGPf6yRI0fqvvvuq3cbeTXM62zSPS8vTn/MrTWHc0F2jRs/frw++ugjLVq0qMFtZHbKZZddps2bN2v9+vV68MEHNWbMGH366afJ2/3IKpDP1mlJxo8fr1/+8pdnXadXr17J/+7atau6du2qSy+9VJdffrny8/O1fv16DRgwQDk5Ofrwww/r3ffw4cNKJBINmmRL5TWvffv2adCgQckPgPw68jrp63mdTWvIqym6du2qzMzMBv8nduDAgVaVw7nIycmRdPJsQG5ubnI52UkTJkzQsmXLtGbNGvXo0SO5nMwaatu2rS6++GJJUv/+/bVhwwY9++yzmjx5siR/smr15aSubJyLujMm8XhckjRgwADNmDFDX375ZfIbs2LFCkUiEfXr18+fgVPMS1579+7VoEGD1K9fPy1cuFAZGfVP1JGXN60hr6Zo27at+vXrp1gspp/+9KfJ5bFYTMOHD0/hZPYVFBQoJydHsVhMV199taST7+FZvXq1Zs+eneLpUsM5pwkTJmjJkiVatWqVCgoK6t1OZt/MOad4PO5vVn68U7c1+PDDD938+fNdeXm527lzp3vvvffcwIED3UUXXeS++uor55xzJ06ccIWFhe7mm292mzZtcv/4xz9cjx493Pjx41M8/bdv79697uKLL3Y33XST++KLL9yXX36ZvNQhr/p27drlysvL3fTp0915553nysvLXXl5uTty5Ihzjry+bvHixS4cDru//OUv7tNPP3UTJ050HTp0cDt37kz1aCl35MiR5LEjyc2dO9eVl5e7Xbt2OeecmzVrluvUqZN744033JYtW9wdd9zhcnNzXVVVVYonT40HH3zQderUya1atare61R1dXVyHTI7ZerUqW7NmjVux44d7qOPPnKPPfaYy8jIcCtWrHDO+ZcV5aSJPvroIzdo0CDXuXNnF4lEXK9evdzYsWPdF198UW+9Xbt2uaFDh7r27du7zp07u/HjxyfLS2uycOFCJ6nRy9eR1yljxoxpNK+VK1cm1yGvU/74xz+6Cy+80LVt29b94Ac/SP7pZ2u3cuXKRo+jMWPGOOdO/mnstGnTXE5OjotEIu7GG290W7ZsSe3QKXSm16mFCxcm1yGzU+65557k8+473/mOu/nmm5PFxDn/sgo597V3cwIAAKRYq/9rHQAAYAvlBAAAmEI5AQAAplBOAACAKZQTAABgCuUEAACYQjkBAACmUE4AAIAplBMAAGAK5QQAAJhCOQEAAKZQTgAAgCn/D0YBgpI7XYuTAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res[res['accurate']]['prob_sum'].hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5a030acc-067f-49b2-9932-eb28aeddd6e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99e0a94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions_as_ids = np.argsort(-test_predictions, 1)\n",
    "predictions_as_ids[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f101ff2d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions_as_ids' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m predictions_as_answer_letters \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mABCDE\u001b[39m\u001b[38;5;124m'\u001b[39m))[\u001b[43mpredictions_as_ids\u001b[49m]\n\u001b[1;32m      2\u001b[0m predictions_as_answer_letters[:\u001b[38;5;241m3\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predictions_as_ids' is not defined"
     ]
    }
   ],
   "source": [
    "predictions_as_answer_letters = np.array(list('ABCDE'))[predictions_as_ids]\n",
    "predictions_as_answer_letters[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "591ead9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D B C', 'A E B', 'A C E']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_as_string = df_test['prediction'] = [\n",
    "    ' '.join(row) for row in predictions_as_answer_letters[:, :3]\n",
    "]\n",
    "predictions_as_string[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb36aac-1eeb-4096-9bf6-afdd3f7bd0f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
